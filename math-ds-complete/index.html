<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mathematics Mastery Platform - Statistics, Linear Algebra &amp; Calculus</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <div class="nav-container">
            <h1 class="course-title">📊 Mathematics Mastery Platform</h1>
            <div class="subject-tabs">
                <button class="subject-tab active" data-subject="statistics">📊 Statistics</button>
                <button class="subject-tab" data-subject="linear-algebra">📐 Linear Algebra</button>
                <button class="subject-tab" data-subject="calculus">∫ Calculus</button>
                <button class="subject-tab" data-subject="data-science">🤖 Data Science</button>
            </div>
            <button class="mobile-menu-btn" id="mobileMenuBtn">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </nav>

    <!-- Main Container -->
    <div class="main-container">
        <!-- Sidebar Navigation -->
        <aside class="sidebar" id="sidebar">
            <div class="sidebar-content">
                <h3 id="sidebarTitle">Statistics Content</h3>
                
                <div class="module">
                    <h4 class="module-title">Module 1: Introduction</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-1" class="topic-link" data-topic="1">📊 What is Statistics</a></li>
                        <li><a href="#topic-2" class="topic-link" data-topic="2">👥 Population vs Sample</a></li>
                        <li><a href="#topic-3" class="topic-link" data-topic="3">📈 Parameters vs Statistics</a></li>
                        <li><a href="#topic-4" class="topic-link" data-topic="4">🔢 Types of Data</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 2: Descriptive Statistics</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-5" class="topic-link" data-topic="5">📍 Central Tendency</a></li>
                        <li><a href="#topic-6" class="topic-link" data-topic="6">⚡ Outliers</a></li>
                        <li><a href="#topic-7" class="topic-link" data-topic="7">📏 Variance &amp; Std Dev</a></li>
                        <li><a href="#topic-8" class="topic-link" data-topic="8">🎯 Quartiles &amp; Percentiles</a></li>
                        <li><a href="#topic-9" class="topic-link" data-topic="9">📦 Interquartile Range</a></li>
                        <li><a href="#topic-10" class="topic-link" data-topic="10">📉 Skewness</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 3: Correlation</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-11" class="topic-link" data-topic="11">🔗 Covariance</a></li>
                        <li><a href="#topic-12" class="topic-link" data-topic="12">💞 Correlation</a></li>
                        <li><a href="#topic-13" class="topic-link" data-topic="13">💪 Correlation Strength</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 4: Probability</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-14" class="topic-link" data-topic="14">🎲 Probability Basics</a></li>
                        <li><a href="#topic-15" class="topic-link" data-topic="15">🔷 Set Theory</a></li>
                        <li><a href="#topic-16" class="topic-link" data-topic="16">🔀 Conditional Probability</a></li>
                        <li><a href="#topic-17" class="topic-link" data-topic="17">🎯 Independence</a></li>
                        <li><a href="#topic-18" class="topic-link" data-topic="18">🧮 Bayes' Theorem</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 5: Distributions</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-19" class="topic-link" data-topic="19">📊 PMF</a></li>
                        <li><a href="#topic-20" class="topic-link" data-topic="20">📈 PDF</a></li>
                        <li><a href="#topic-21" class="topic-link" data-topic="21">📉 CDF</a></li>
                        <li><a href="#topic-22" class="topic-link" data-topic="22">🪙 Bernoulli Distribution</a></li>
                        <li><a href="#topic-23" class="topic-link" data-topic="23">🎰 Binomial Distribution</a></li>
                        <li><a href="#topic-24" class="topic-link" data-topic="24">🔔 Normal Distribution</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 6: Hypothesis Testing</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-25" class="topic-link" data-topic="25">⚖️ Hypothesis Testing Intro</a></li>
                        <li><a href="#topic-26" class="topic-link" data-topic="26">🎯 Significance Level α</a></li>
                        <li><a href="#topic-27" class="topic-link" data-topic="27">📊 Standard Error</a></li>
                        <li><a href="#topic-28" class="topic-link" data-topic="28">📏 Z-Test</a></li>
                        <li><a href="#topic-29" class="topic-link" data-topic="29">🎚️ Z-Score &amp; Critical Values</a></li>
                        <li><a href="#topic-30" class="topic-link" data-topic="30">💯 P-Value</a></li>
                        <li><a href="#topic-31" class="topic-link" data-topic="31">↔️ One vs Two Tailed</a></li>
                        <li><a href="#topic-32" class="topic-link" data-topic="32">📐 T-Test</a></li>
                        <li><a href="#topic-33" class="topic-link" data-topic="33">🔓 Degrees of Freedom</a></li>
                        <li><a href="#topic-34" class="topic-link" data-topic="34">⚠️ Type I &amp; II Errors</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 7: Chi-Squared Tests</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-35" class="topic-link" data-topic="35">χ² Chi-Squared Distribution</a></li>
                        <li><a href="#topic-36" class="topic-link" data-topic="36">✓ Goodness of Fit</a></li>
                        <li><a href="#topic-37" class="topic-link" data-topic="37">🔗 Test of Independence</a></li>
                        <li><a href="#topic-38" class="topic-link" data-topic="38">📏 Variance Testing</a></li>
                    </ul>
                </div>

                <div class="module">
                    <h4 class="module-title">Module 8: Confidence Intervals</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-39" class="topic-link" data-topic="39">📊 Confidence Intervals</a></li>
                        <li><a href="#topic-40" class="topic-link" data-topic="40">± Margin of Error</a></li>
                        <li><a href="#topic-41" class="topic-link" data-topic="41">🔍 Interpreting CIs</a></li>
                    </ul>
                </div>

                <!-- Linear Algebra Modules (Hidden by default) -->
                <div class="module" data-subject="linear-algebra" style="display: none;">
                    <h4 class="module-title">Module 9: Introduction to Linear Algebra</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-42" class="topic-link" data-topic="42">➡️ Vectors - What Even Are They?</a></li>
                        <li><a href="#topic-43" class="topic-link" data-topic="43">🎯 Linear Combinations, Span, Basis</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="linear-algebra" style="display: none;">
                    <h4 class="module-title">Module 10: Transformations &amp; Matrices</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-44" class="topic-link" data-topic="44">🔄 Linear Transformations</a></li>
                        <li><a href="#topic-45" class="topic-link" data-topic="45">🔗 Matrix Multiplication</a></li>
                        <li><a href="#topic-46" class="topic-link" data-topic="46">🎲 3D Transformations</a></li>
                        <li><a href="#topic-47" class="topic-link" data-topic="47">📏 The Determinant</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="linear-algebra" style="display: none;">
                    <h4 class="module-title">Module 11: Systems &amp; Inverses</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-48" class="topic-link" data-topic="48">↩️ Inverse Matrices</a></li>
                        <li><a href="#topic-49" class="topic-link" data-topic="49">🔀 Nonsquare Matrices</a></li>
                        <li><a href="#topic-50" class="topic-link" data-topic="50">• Dot Products &amp; Duality</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="linear-algebra" style="display: none;">
                    <h4 class="module-title">Module 12: Cross Products &amp; Advanced</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-51" class="topic-link" data-topic="51">✖️ Cross Products</a></li>
                        <li><a href="#topic-52" class="topic-link" data-topic="52">🔄 Cross via Transformations</a></li>
                        <li><a href="#topic-53" class="topic-link" data-topic="53">🔄 Change of Basis</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="linear-algebra" style="display: none;">
                    <h4 class="module-title">Module 13: Eigenvalues &amp; Eigenvectors</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-54" class="topic-link" data-topic="54">🎯 Eigenvectors &amp; Eigenvalues</a></li>
                        <li><a href="#topic-55" class="topic-link" data-topic="55">⚡ Eigenvalue Quick Trick</a></li>
                        <li><a href="#topic-56" class="topic-link" data-topic="56">∞ Abstract Vector Spaces</a></li>
                        <li><a href="#topic-57" class="topic-link" data-topic="57">📐 Cramer's Rule</a></li>
                    </ul>
                </div>

                <!-- Calculus Modules (Hidden by default) -->
                <div class="module" data-subject="calculus" style="display: none;">
                    <h4 class="module-title">Module 14: Introduction to Calculus</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-58" class="topic-link" data-topic="58">🎯 The Essence of Calculus</a></li>
                        <li><a href="#topic-59" class="topic-link" data-topic="59">🤔 Paradox of the Derivative</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="calculus" style="display: none;">
                    <h4 class="module-title">Module 15: Derivatives</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-60" class="topic-link" data-topic="60">📐 Derivative Formulas</a></li>
                        <li><a href="#topic-61" class="topic-link" data-topic="61">🔗 Chain &amp; Product Rule</a></li>
                        <li><a href="#topic-62" class="topic-link" data-topic="62">ℯ Derivative of eˣ</a></li>
                        <li><a href="#topic-63" class="topic-link" data-topic="63">🔄 Implicit Differentiation</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="calculus" style="display: none;">
                    <h4 class="module-title">Module 16: Integrals</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-64" class="topic-link" data-topic="64">∫ Integrals</a></li>
                        <li><a href="#topic-65" class="topic-link" data-topic="65">⚖️ Fundamental Theorem</a></li>
                        <li><a href="#topic-66" class="topic-link" data-topic="66">📊 Area &amp; Slope Connection</a></li>
                        <li><a href="#topic-67" class="topic-link" data-topic="67">📈 Higher Order Derivatives</a></li>
                        <li><a href="#topic-68" class="topic-link" data-topic="68">∞ Taylor Series</a></li>
                        <li><a href="#topic-69" class="topic-link" data-topic="69">∞ Limits (ε-δ Definition)</a></li>
                    </ul>
                </div>

                <!-- Data Science Modules (Hidden by default) -->
                <div class="module" data-subject="data-science" style="display: none;">
                    <h4 class="module-title">Module 17: Regression &amp; Modeling</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-70" class="topic-link" data-topic="70">70. Simple Linear Regression</a></li>
                        <li><a href="#topic-71" class="topic-link" data-topic="71">71. Multiple Regression</a></li>
                        <li><a href="#topic-72" class="topic-link" data-topic="72">72. Logistic Regression</a></li>
                        <li><a href="#topic-73" class="topic-link" data-topic="73">73. ANOVA</a></li>
                        <li><a href="#topic-74" class="topic-link" data-topic="74">74. Polynomial Regression</a></li>
                        <li><a href="#topic-75" class="topic-link" data-topic="75">75. R² &amp; Model Evaluation</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="data-science" style="display: none;">
                    <h4 class="module-title">Module 18: Advanced Linear Algebra</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-76" class="topic-link" data-topic="76">76. SVD</a></li>
                        <li><a href="#topic-77" class="topic-link" data-topic="77">77. PCA</a></li>
                        <li><a href="#topic-78" class="topic-link" data-topic="78">78. Matrix Decompositions</a></li>
                        <li><a href="#topic-79" class="topic-link" data-topic="79">79. Norms &amp; Distance</a></li>
                    </ul>
                </div>

                <div class="module" data-subject="data-science" style="display: none;">
                    <h4 class="module-title">Module 19: Optimization</h4>
                    <ul class="topic-list">
                        <li><a href="#topic-80" class="topic-link" data-topic="80">80. Gradient Descent</a></li>
                        <li><a href="#topic-81" class="topic-link" data-topic="81">81. SGD</a></li>
                        <li><a href="#topic-82" class="topic-link" data-topic="82">82. Partial Derivatives</a></li>
                        <li><a href="#topic-83" class="topic-link" data-topic="83">83. Gradient &amp; Jacobian</a></li>
                        <li><a href="#topic-84" class="topic-link" data-topic="84">84. Convex Optimization</a></li>
                        <li><a href="#topic-85" class="topic-link" data-topic="85">85. Loss Functions</a></li>
                    </ul>
                </div>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="content" id="content">
            <!-- Topic 1: What is Statistics -->
            <section class="topic-section" id="topic-1">
                <div class="topic-header">
                    <span class="topic-number">Topic 1</span>
                    <h2>📊 What is Statistics &amp; Why It Matters</h2>
                    <p class="topic-subtitle">The science of collecting, organizing, analyzing, and interpreting data</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Statistics is a branch of mathematics that deals with data. It provides methods to make sense of numbers and help us make informed decisions based on evidence rather than guesswork.</p>
                    <p><strong>Why it matters:</strong> From business forecasting to medical research, sports analysis to government policy, statistics powers nearly every decision in our modern world.</p>
                    <p><strong>When to use it:</strong> Whenever you need to understand patterns, test theories, make predictions, or draw conclusions from data.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>Imagine Netflix deciding what shows to produce. They analyze viewing statistics: what genres people watch, when they pause, what they finish. Statistics transforms millions of data points into actionable insights like "Create more thriller series" or "Release episodes on Fridays."</p>
                </div>

                <div class="content-card">
                    <h3>Two Branches of Statistics</h3>
                    <div class="two-column">
                        <div class="column">
                            <h4 style="color: #64ffda;">Descriptive Statistics</h4>
                            <ul>
                                <li>Summarizes and describes data</li>
                                <li>Uses charts, graphs, averages</li>
                                <li>Example: "Average class score is 85"</li>
                            </ul>
                        </div>
                        <div class="column">
                            <h4 style="color: #ff6b6b;">Inferential Statistics</h4>
                            <ul>
                                <li>Makes predictions and inferences</li>
                                <li>Tests hypotheses</li>
                                <li>Example: "New teaching method improves scores"</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Use Cases &amp; Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Healthcare:</strong> Clinical trials testing new drugs, disease outbreak tracking</li>
                        <li><strong>Business:</strong> Customer behavior analysis, sales forecasting, A/B testing</li>
                        <li><strong>Government:</strong> Census data, economic indicators, policy impact assessment</li>
                        <li><strong>Sports:</strong> Player performance metrics, game strategy optimization</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Statistics transforms raw data into meaningful insights</li>
                        <li>Two main branches: Descriptive (what happened) and Inferential (what will happen)</li>
                        <li>Essential for decision-making across all fields</li>
                        <li>Combines mathematics with real-world problem solving</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 2: Population vs Sample -->
            <section class="topic-section" id="topic-2">
                <div class="topic-header">
                    <span class="topic-number">Topic 2</span>
                    <h2>👥 Population vs Sample</h2>
                    <p class="topic-subtitle">Understanding the difference between the entire group and a subset</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A <em>population</em> includes ALL members of a defined group. A <em>sample</em> is a subset selected from that population.</p>
                    <p><strong>Why it matters:</strong> It's usually impossible or impractical to study entire populations. Sampling allows us to make inferences about large groups by studying smaller representative groups.</p>
                    <p><strong>When to use it:</strong> Use populations when you can access all data; use samples when populations are too large, expensive, or time-consuming to study.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD ANALOGY</div>
                    <p>Think of tasting soup. You don't need to eat the entire pot (population) to know if it needs salt. A single spoonful (sample) gives you a good idea—as long as you stirred it well first!</p>
                </div>

                <div class="interactive-container">
                    <h3>Interactive Visualization</h3>
                    <canvas id="populationSampleCanvas" width="800" height="400"></canvas>
                    <div class="controls">
                        <button class="btn btn-primary" id="sampleBtn">Take Sample</button>
                        <button class="btn btn-secondary" id="resetPopBtn">Reset</button>
                        <div class="slider-group">
                            <label>Sample Size: <span id="sampleSizeLabel">30</span></label>
                            <input type="range" id="sampleSizeSlider" min="10" max="100" value="30" class="slider">
                        </div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Key Differences</h3>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Aspect</th>
                                <th>Population</th>
                                <th>Sample</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Size</td>
                                <td>Entire group (N)</td>
                                <td>Subset (n)</td>
                            </tr>
                            <tr>
                                <td>Symbol</td>
                                <td>N (uppercase)</td>
                                <td>n (lowercase)</td>
                            </tr>
                            <tr>
                                <td>Cost</td>
                                <td>High</td>
                                <td>Lower</td>
                            </tr>
                            <tr>
                                <td>Time</td>
                                <td>Long</td>
                                <td>Shorter</td>
                            </tr>
                            <tr>
                                <td>Accuracy</td>
                                <td>100% (if measured correctly)</td>
                                <td>Has sampling error</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKE</div>
                    <p><strong>Biased Sampling:</strong> If your sample doesn't represent the population, your conclusions will be wrong. Example: Surveying only morning shoppers at a store will miss evening customer patterns.</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIP</div>
                    <p>For a sample to be representative, use <strong>random sampling</strong>. Every member of the population should have an equal chance of being selected.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li><strong>Population (N):</strong> All members of a defined group</li>
                        <li><strong>Sample (n):</strong> A subset selected from the population</li>
                        <li>Good samples are <em>random</em> and <em>representative</em></li>
                        <li>Larger samples generally provide better estimates</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 3: Parameters vs Statistics -->
            <section class="topic-section" id="topic-3">
                <div class="topic-header">
                    <span class="topic-number">Topic 3</span>
                    <h2>📈 Parameters vs Statistics</h2>
                    <p class="topic-subtitle">Population measures vs sample measures</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A <em>parameter</em> is a numerical characteristic of a <em>population</em>. A <em>statistic</em> is a numerical characteristic of a <em>sample</em>.</p>
                    <p><strong>Why it matters:</strong> We usually can't measure parameters directly (populations are too large), so we estimate them using statistics from samples.</p>
                    <p><strong>When to use it:</strong> Parameters are what we want to know; statistics are what we can calculate.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>You want to know the average height of all students in your country (parameter). You can't measure everyone, so you measure 1,000 students (sample) and calculate their average height (statistic) to estimate the population parameter.</p>
                </div>

                <div class="content-card">
                    <h3>Common Parameters and Statistics</h3>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Measure</th>
                                <th>Parameter (Population)</th>
                                <th>Statistic (Sample)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Mean (Average)</td>
                                <td>μ (mu)</td>
                                <td>x̄ (x-bar)</td>
                            </tr>
                            <tr>
                                <td>Standard Deviation</td>
                                <td>σ (sigma)</td>
                                <td>s</td>
                            </tr>
                            <tr>
                                <td>Variance</td>
                                <td>σ²</td>
                                <td>s²</td>
                            </tr>
                            <tr>
                                <td>Proportion</td>
                                <td>p</td>
                                <td>p̂ (p-hat)</td>
                            </tr>
                            <tr>
                                <td>Size</td>
                                <td>N</td>
                                <td>n</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="content-card">
                    <h3>The Relationship</h3>
                    <div class="formula-card">
                        <div class="formula-header">Key Concept</div>
                        <p style="text-align: center; font-size: 1.2em; margin: 20px 0;">
                            <span style="color: #ff6b6b;">Statistic</span> → Estimates → <span style="color: #64ffda;">Parameter</span>
                        </p>
                        <p>We use <strong>statistics</strong> (calculated from samples) to <strong>estimate parameters</strong> (unknown population values).</p>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <div>
                        <p><strong>Scenario:</strong> A factory wants to know the average weight of cereal boxes.</p>
                        <ul>
                            <li><strong>Population:</strong> All cereal boxes produced (millions)</li>
                            <li><strong>Parameter:</strong> μ = true average weight of ALL boxes (unknown)</li>
                            <li><strong>Sample:</strong> 100 randomly selected boxes</li>
                            <li><strong>Statistic:</strong> x̄ = 510 grams (calculated from the 100 boxes)</li>
                            <li><strong>Inference:</strong> We estimate μ ≈ 510 grams</li>
                        </ul>
                    </div>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKE</div>
                    <p>Confusing symbols! Greek letters (μ, σ, ρ) refer to <strong>parameters</strong> (population). Roman letters (x̄, s, r) refer to <strong>statistics</strong> (sample).</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li><strong>Parameter:</strong> Describes a population (usually unknown)</li>
                        <li><strong>Statistic:</strong> Describes a sample (calculated from data)</li>
                        <li>Greek letters = population, Roman letters = sample</li>
                        <li>Statistics are used to estimate parameters</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 4: Types of Data -->
            <section class="topic-section" id="topic-4">
                <div class="topic-header">
                    <span class="topic-number">Topic 4</span>
                    <h2>🔢 Types of Data</h2>
                    <p class="topic-subtitle">Categorical, Numerical, Discrete, Continuous, Ordinal, Nominal</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Data comes in different types, and understanding these types determines which statistical methods you can use.</p>
                    <p><strong>Why it matters:</strong> Using the wrong analysis method for your data type leads to incorrect conclusions. You can't calculate an average of colors!</p>
                    <p><strong>When to use it:</strong> Before any analysis, identify your data type to choose appropriate statistical techniques.</p>
                </div>

                <div class="content-card">
                    <h3>Data Type Hierarchy</h3>
                    <div class="data-tree">
                        <div class="tree-level-1">
                            <div class="tree-node main">DATA</div>
                        </div>
                        <div class="tree-level-2">
                            <div class="tree-node categorical">CATEGORICAL</div>
                            <div class="tree-node numerical">NUMERICAL</div>
                        </div>
                        <div class="tree-level-3">
                            <div class="tree-node">Nominal</div>
                            <div class="tree-node">Ordinal</div>
                            <div class="tree-node">Discrete</div>
                            <div class="tree-node">Continuous</div>
                        </div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Categorical Data</h3>
                    <p>Represents categories or groups (qualitative)</p>
                    
                    <div class="two-column">
                        <div class="column">
                            <h4 style="color: #64ffda;">Nominal</h4>
                            <p>Categories with NO order</p>
                            <ul>
                                <li>Colors: Red, Blue, Green</li>
                                <li>Gender: Male, Female, Non-binary</li>
                                <li>Country: USA, India, Japan</li>
                                <li>Blood Type: A, B, AB, O</li>
                            </ul>
                        </div>
                        <div class="column">
                            <h4 style="color: #ff6b6b;">Ordinal</h4>
                            <p>Categories WITH meaningful order</p>
                            <ul>
                                <li>Education: High School &lt; Bachelor's &lt; Master's</li>
                                <li>Satisfaction: Poor &lt; Fair &lt; Good &lt; Excellent</li>
                                <li>Medal: Bronze &lt; Silver &lt; Gold</li>
                                <li>Size: Small &lt; Medium &lt; Large</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Numerical Data</h3>
                    <p>Represents quantities (quantitative)</p>
                    
                    <div class="two-column">
                        <div class="column">
                            <h4 style="color: #64ffda;">Discrete</h4>
                            <p>Countable, specific values only</p>
                            <ul>
                                <li>Number of students: 25, 30, 42</li>
                                <li>Number of cars: 0, 1, 2, 3...</li>
                                <li>Dice roll: 1, 2, 3, 4, 5, 6</li>
                                <li>Number of children: 0, 1, 2, 3...</li>
                            </ul>
                            <p><em>Can't have 2.5 students!</em></p>
                        </div>
                        <div class="column">
                            <h4 style="color: #ff6b6b;">Continuous</h4>
                            <p>Can take any value in a range</p>
                            <ul>
                                <li>Height: 165.3 cm, 180.7 cm</li>
                                <li>Weight: 68.5 kg, 72.3 kg</li>
                                <li>Temperature: 23.4°C, 24.7°C</li>
                                <li>Time: 3.25 seconds</li>
                            </ul>
                            <p><em>Infinite precision possible</em></p>
                        </div>
                    </div>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 QUICK TEST</div>
                    <p><strong>Ask yourself:</strong></p>
                    <ol>
                        <li><strong>Is it a label/category?</strong> → Categorical</li>
                        <li><strong>Is it a number?</strong> → Numerical</li>
                        <li><strong>Can you count it?</strong> → Discrete</li>
                        <li><strong>Can you measure it?</strong> → Continuous</li>
                        <li><strong>Does order matter?</strong> → Ordinal (else Nominal)</li>
                    </ol>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLES</div>
                    <table class="data-examples-table">
                        <thead>
                            <tr>
                                <th>Data</th>
                                <th>Type</th>
                                <th>Reason</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Zip codes</td>
                                <td>Categorical (Nominal)</td>
                                <td>Numbers used as labels, not quantities</td>
                            </tr>
                            <tr>
                                <td>Test scores (A, B, C, D, F)</td>
                                <td>Categorical (Ordinal)</td>
                                <td>Categories with clear order</td>
                            </tr>
                            <tr>
                                <td>Number of pages in books</td>
                                <td>Numerical (Discrete)</td>
                                <td>Countable whole numbers</td>
                            </tr>
                            <tr>
                                <td>Reaction time in milliseconds</td>
                                <td>Numerical (Continuous)</td>
                                <td>Can be measured to any precision</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKE</div>
                    <p>Just because something is written as a number doesn't make it numerical! Phone numbers, jersey numbers, and zip codes are <strong>categorical</strong> because they identify categories, not quantities.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li><strong>Categorical:</strong> Labels/categories (Nominal: no order, Ordinal: has order)</li>
                        <li><strong>Numerical:</strong> Quantities (Discrete: countable, Continuous: measurable)</li>
                        <li>Data type determines which statistical methods to use</li>
                        <li>Always identify data type before analysis</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 5: Measures of Central Tendency -->
            <section class="topic-section" id="topic-5">
                <div class="topic-header">
                    <span class="topic-number">Topic 5</span>
                    <h2>📍 Measures of Central Tendency</h2>
                    <p class="topic-subtitle">Mean, Median, Mode - Finding the center of data</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Measures of central tendency are single values that represent the "center" or "typical" value in a dataset.</p>
                    <p><strong>Why it matters:</strong> Instead of looking at hundreds of numbers, one central value summarizes the data. "Average salary" tells you more than listing every employee's salary.</p>
                    <p><strong>When to use it:</strong> When you need to summarize data with a single representative value.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD ANALOGY</div>
                    <p>Imagine finding the "center" of a group of people standing on a field. Mean is like finding the balance point where they'd balance on a seesaw. Median is literally the middle person. Mode is where the most people are clustered together.</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundations</h3>
                    
                    <div class="formula-card">
                        <div class="formula-header">Mean (Average)</div>
                        <div class="formula-main">
                            <span class="formula-symbol">μ</span> = 
                            <span class="formula-fraction">
                                <span class="formula-numerator">Σx</span>
                                <span class="formula-line"></span>
                                <span class="formula-denominator">n</span>
                            </span>
                        </div>
                        <p><strong>Where:</strong></p>
                        <ul>
                            <li><span class="formula-var">μ</span> (mu) = population mean or <span class="formula-var">x̄</span> (x-bar) = sample mean</li>
                            <li><span class="formula-var">Σx</span> = sum of all values</li>
                            <li><span class="formula-var">n</span> = number of values</li>
                        </ul>
                        <div class="formula-steps">
                            <p><strong>Steps:</strong></p>
                            <ol>
                                <li>Add all values together</li>
                                <li>Divide by the count of values</li>
                            </ol>
                        </div>
                    </div>

                    <div class="formula-card">
                        <div class="formula-header">Median (Middle Value)</div>
                        <div class="formula-main">
                            <p>If <strong>odd</strong> number of values: Middle value</p>
                            <p>If <strong>even</strong> number of values: Average of two middle values</p>
                        </div>
                        <div class="formula-steps">
                            <p><strong>Steps:</strong></p>
                            <ol>
                                <li>Sort values in ascending order</li>
                                <li>Find the middle position: (n + 1) / 2</li>
                                <li>If between two values, average them</li>
                            </ol>
                        </div>
                    </div>

                    <div class="formula-card">
                        <div class="formula-header">Mode (Most Frequent)</div>
                        <div class="formula-main">
                            <p>The value(s) that appear most frequently</p>
                        </div>
                        <div class="formula-steps">
                            <p><strong>Types:</strong></p>
                            <ul>
                                <li><strong>Unimodal:</strong> One mode</li>
                                <li><strong>Bimodal:</strong> Two modes</li>
                                <li><strong>Multimodal:</strong> More than two modes</li>
                                <li><strong>No mode:</strong> All values appear equally</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Interactive Calculator</h3>
                    <canvas id="centralTendencyCanvas" width="800" height="300"></canvas>
                    <div class="controls">
                        <div class="input-group">
                            <label>Enter values (comma-separated):</label>
                            <input type="text" id="centralTendencyInput" value="10, 20, 30, 40, 50" class="form-control">
                            <button class="btn btn-primary" id="calculateCentralBtn">Calculate</button>
                            <button class="btn btn-secondary" id="randomDataBtn">Random Data</button>
                        </div>
                        <div class="results" id="centralTendencyResults">
                            <div class="result-item"><span class="result-label">Mean:</span> <span id="meanResult">30</span></div>
                            <div class="result-item"><span class="result-label">Median:</span> <span id="medianResult">30</span></div>
                            <div class="result-item"><span class="result-label">Mode:</span> <span id="modeResult">None</span></div>
                        </div>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 WORKED EXAMPLE</div>
                    <p><strong>Dataset:</strong> Test scores: 65, 70, 75, 80, 85, 90, 95</p>
                    <div class="example-solution">
                        <p><strong>Mean:</strong></p>
                        <p>Sum = 65 + 70 + 75 + 80 + 85 + 90 + 95 = 560</p>
                        <p>Mean = 560 / 7 = <strong>80</strong></p>
                        
                        <p><strong>Median:</strong></p>
                        <p>Already sorted. Middle position = (7 + 1) / 2 = 4th value</p>
                        <p>Median = <strong>80</strong></p>
                        
                        <p><strong>Mode:</strong></p>
                        <p>All values appear once. <strong>No mode</strong></p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>When to Use Which?</h3>
                    <div class="comparison-grid">
                        <div class="comparison-item">
                            <h4 style="color: #64ffda;">Use Mean</h4>
                            <ul>
                                <li>Data is symmetrical</li>
                                <li>No extreme outliers</li>
                                <li>Numerical data</li>
                                <li>Need to use all data points</li>
                            </ul>
                        </div>
                        <div class="comparison-item">
                            <h4 style="color: #ff6b6b;">Use Median</h4>
                            <ul>
                                <li>Data has outliers</li>
                                <li>Data is skewed</li>
                                <li>Ordinal data</li>
                                <li>Need robust measure</li>
                            </ul>
                        </div>
                        <div class="comparison-item">
                            <h4 style="color: #4a90e2;">Use Mode</h4>
                            <ul>
                                <li>Categorical data</li>
                                <li>Finding most common value</li>
                                <li>Discrete data</li>
                                <li>Multiple peaks in data</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKE</div>
                    <p><strong>Mean is affected by outliers!</strong> In salary data like $30K, $35K, $40K, $45K, $500K, the mean is $130K (misleading!). The median of $40K better represents typical salary.</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIP</div>
                    <p>For skewed data (like income, house prices), <strong>always report the median</strong> along with the mean. If they're very different, your data has outliers or is skewed!</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li><strong>Mean:</strong> Sum of all values divided by count (affected by outliers)</li>
                        <li><strong>Median:</strong> Middle value when sorted (resistant to outliers)</li>
                        <li><strong>Mode:</strong> Most frequent value (useful for categorical data)</li>
                        <li>Choose the measure that best represents your data type and distribution</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 6: Outliers -->
            <section class="topic-section" id="topic-6">
                <div class="topic-header">
                    <span class="topic-number">Topic 6</span>
                    <h2>⚡ Outliers</h2>
                    <p class="topic-subtitle">Extreme values that don't fit the pattern</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Outliers are data points that are significantly different from other observations in a dataset.</p>
                    <p><strong>Why it matters:</strong> Outliers can indicate data errors, special cases, or important patterns. They can also severely distort statistical analyses.</p>
                    <p><strong>When to use it:</strong> Always check for outliers before analyzing data, especially when calculating means and standard deviations.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>In a salary dataset for entry-level employees: $35K, $38K, $40K, $37K, $250K. The $250K is an outlier—maybe it's a data entry error (someone added an extra zero) or a special case (CEO's child). Either way, it needs investigation!</p>
                </div>

                <div class="content-card">
                    <h3>Detection Methods</h3>
                    <div class="two-column">
                        <div class="column">
                            <h4 style="color: #64ffda;">IQR Method</h4>
                            <p>Most common approach:</p>
                            <ul>
                                <li>Calculate Q1, Q3, and IQR = Q3 - Q1</li>
                                <li>Lower fence = Q1 - 1.5 × IQR</li>
                                <li>Upper fence = Q3 + 1.5 × IQR</li>
                                <li>Outliers fall outside fences</li>
                            </ul>
                        </div>
                        <div class="column">
                            <h4 style="color: #ff6b6b;">Z-Score Method</h4>
                            <p>For normal distributions:</p>
                            <ul>
                                <li>Calculate z-score for each value</li>
                                <li>z = (x - μ) / σ</li>
                                <li>If |z| &gt; 3: definitely outlier</li>
                                <li>If |z| &gt; 2: possible outlier</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKE</div>
                    <p>Never automatically delete outliers! They might be: (1) Valid extreme values, (2) Data entry errors, (3) Important discoveries. Always investigate before removing.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Outliers are extreme values that differ significantly from other data</li>
                        <li>Use IQR method (1.5 × IQR rule) or Z-score method to detect</li>
                        <li>Mean is heavily affected by outliers; median is resistant</li>
                        <li>Always investigate outliers before deciding to keep or remove</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 7: Variance & Standard Deviation -->
            <section class="topic-section" id="topic-7">
                <div class="topic-header">
                    <span class="topic-number">Topic 7</span>
                    <h2>📏 Variance &amp; Standard Deviation</h2>
                    <p class="topic-subtitle">Measuring spread and variability in data</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Variance measures the average squared deviation from the mean. Standard deviation is the square root of variance.</p>
                    <p><strong>Why it matters:</strong> Shows how spread out data is. Low values mean data is clustered; high values mean data is scattered.</p>
                    <p><strong>When to use it:</strong> Whenever you need to understand data variability—in finance (risk), manufacturing (quality control), or research (reliability).</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Formulas</h3>
                    <div class="formula-card">
                        <div class="formula-header">Population Variance (σ²)</div>
                        <div class="formula-main">σ² = Σ(x - μ)² / N</div>
                        <p>Where N = population size, μ = population mean</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Sample Variance (s²)</div>
                        <div class="formula-main">s² = Σ(x - x̄)² / (n - 1)</div>
                        <p>Where n = sample size, x̄ = sample mean. We use (n-1) for unbiased estimation.</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Standard Deviation</div>
                        <div class="formula-main">σ = √(variance)</div>
                        <p>Same units as original data, easier to interpret</p>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 WORKED EXAMPLE</div>
                    <p><strong>Dataset:</strong> [4, 8, 6, 5, 3, 7]</p>
                    <div class="example-solution">
                        <p><strong>Step 1:</strong> Mean = (4+8+6+5+3+7)/6 = 5.5</p>
                        <p><strong>Step 2:</strong> Deviations: [-1.5, 2.5, 0.5, -0.5, -2.5, 1.5]</p>
                        <p><strong>Step 3:</strong> Squared: [2.25, 6.25, 0.25, 0.25, 6.25, 2.25]</p>
                        <p><strong>Step 4:</strong> Sum = 17.5</p>
                        <p><strong>Step 5:</strong> Variance = 17.5/(6-1) = 3.5</p>
                        <p><strong>Step 6:</strong> Std Dev = √3.5 = 1.87</p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Variance measures average squared deviation from mean</li>
                        <li>Standard deviation is square root of variance (same units as data)</li>
                        <li>Use (n-1) for sample variance to avoid bias</li>
                        <li>Higher values = more spread; lower values = more clustered</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 8: Quartiles & Percentiles -->
            <section class="topic-section" id="topic-8">
                <div class="topic-header">
                    <span class="topic-number">Topic 8</span>
                    <h2>🎯 Quartiles &amp; Percentiles</h2>
                    <p class="topic-subtitle">Dividing data into equal parts</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Quartiles divide sorted data into 4 equal parts. Percentiles divide data into 100 equal parts.</p>
                    <p><strong>Why it matters:</strong> Shows relative position in a dataset. "90th percentile" means you scored better than 90% of people.</p>
                </div>

                <div class="content-card">
                    <h3>The Five-Number Summary</h3>
                    <ul>
                        <li><strong>Minimum:</strong> Smallest value</li>
                        <li><strong>Q1 (25th percentile):</strong> 25% of data below this</li>
                        <li><strong>Q2 (50th percentile/Median):</strong> Middle value</li>
                        <li><strong>Q3 (75th percentile):</strong> 75% of data below this</li>
                        <li><strong>Maximum:</strong> Largest value</li>
                    </ul>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>SAT scores: If you score 1350 and that's the 90th percentile, it means you scored higher than 90% of test-takers. Percentiles are perfect for standardized tests!</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Q1 = 25th percentile, Q2 = median, Q3 = 75th percentile</li>
                        <li>Percentiles show relative standing in a dataset</li>
                        <li>Five-number summary: Min, Q1, Q2, Q3, Max</li>
                        <li>Useful for understanding data distribution</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 9: Interquartile Range -->
            <section class="topic-section" id="topic-9">
                <div class="topic-header">
                    <span class="topic-number">Topic 9</span>
                    <h2>📦 Interquartile Range (IQR)</h2>
                    <p class="topic-subtitle">Middle 50% of data and outlier detection</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> IQR = Q3 - Q1. It represents the range of the middle 50% of your data.</p>
                    <p><strong>Why it matters:</strong> IQR is resistant to outliers and is the foundation of the 1.5×IQR rule for outlier detection.</p>
                </div>

                <div class="content-card">
                    <h3>The 1.5 × IQR Rule</h3>
                    <div class="formula-card">
                        <div class="formula-header">Outlier Boundaries</div>
                        <div class="formula-main">
                            Lower Fence = Q1 - 1.5 × IQR<br>
                            Upper Fence = Q3 + 1.5 × IQR
                        </div>
                        <p>Any value outside these fences is considered an outlier</p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>IQR = Q3 - Q1 (range of middle 50% of data)</li>
                        <li>Resistant to outliers (unlike standard deviation)</li>
                        <li>1.5×IQR rule: standard method for outlier detection</li>
                        <li>Box plots visualize IQR and outliers</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 10: Skewness -->
            <section class="topic-section" id="topic-10">
                <div class="topic-header">
                    <span class="topic-number">Topic 10</span>
                    <h2>📉 Skewness</h2>
                    <p class="topic-subtitle">Understanding data distribution shape</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Skewness measures the asymmetry of a distribution.</p>
                    <p><strong>Why it matters:</strong> Indicates whether data leans left or right, affecting which statistical methods to use.</p>
                </div>

                <div class="content-card">
                    <h3>Types of Skewness</h3>
                    <div class="comparison-grid">
                        <div class="comparison-item">
                            <h4 style="color: #64ffda;">Negative (Left) Skew</h4>
                            <p>Tail extends to the left</p>
                            <p>Mean &lt; Median &lt; Mode</p>
                            <p>Example: Test scores when most students do well</p>
                        </div>
                        <div class="comparison-item">
                            <h4 style="color: #4a90e2;">Symmetric (No Skew)</h4>
                            <p>Perfectly balanced</p>
                            <p>Mean = Median = Mode</p>
                            <p>Example: Normal distribution</p>
                        </div>
                        <div class="comparison-item">
                            <h4 style="color: #ff6b6b;">Positive (Right) Skew</h4>
                            <p>Tail extends to the right</p>
                            <p>Mode &lt; Median &lt; Mean</p>
                            <p>Example: Income data, house prices</p>
                        </div>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Skewness measures asymmetry in distribution</li>
                        <li>Negative skew: tail to left, Mean &lt; Median</li>
                        <li>Positive skew: tail to right, Mean &gt; Median</li>
                        <li>Symmetric: Mean = Median = Mode</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 11: Covariance -->
            <section class="topic-section" id="topic-11">
                <div class="topic-header">
                    <span class="topic-number">Topic 11</span>
                    <h2>🔗 Covariance</h2>
                    <p class="topic-subtitle">How two variables vary together</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Covariance measures how two variables change together.</p>
                    <p><strong>Why it matters:</strong> Shows if variables have a positive, negative, or no relationship.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Sample Covariance</div>
                        <div class="formula-main">Cov(X,Y) = Σ(xᵢ - x̄)(yᵢ - ȳ) / (n-1)</div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Interpretation</h3>
                    <ul>
                        <li><strong>Positive:</strong> Variables increase together</li>
                        <li><strong>Negative:</strong> One increases as other decreases</li>
                        <li><strong>Zero:</strong> No linear relationship</li>
                        <li><strong>Problem:</strong> Scale-dependent, hard to interpret magnitude</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Covariance measures joint variability of two variables</li>
                        <li>Positive: variables move together; Negative: inverse relationship</li>
                        <li>Scale-dependent (unlike correlation)</li>
                        <li>Foundation for correlation calculation</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 12: Correlation -->
            <section class="topic-section" id="topic-12">
                <div class="topic-header">
                    <span class="topic-number">Topic 12</span>
                    <h2>💞 Correlation</h2>
                    <p class="topic-subtitle">Standardized measure of relationship strength</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Correlation coefficient (r) is a standardized measure of linear relationship between two variables.</p>
                    <p><strong>Why it matters:</strong> Always between -1 and +1, making it easy to interpret strength and direction of relationships.</p>
                </div>

                <div class="content-card">
                    <h3>Pearson Correlation Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Correlation Coefficient (r)</div>
                        <div class="formula-main">r = Cov(X,Y) / (σₓ × σᵧ)</div>
                        <p>Covariance divided by product of standard deviations</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Interpretation Guide</h3>
                    <ul>
                        <li><strong>r = +1:</strong> Perfect positive correlation</li>
                        <li><strong>r = 0.7 to 0.9:</strong> Strong positive</li>
                        <li><strong>r = 0.4 to 0.6:</strong> Moderate positive</li>
                        <li><strong>r = 0.1 to 0.3:</strong> Weak positive</li>
                        <li><strong>r = 0:</strong> No correlation</li>
                        <li><strong>r = -0.1 to -0.3:</strong> Weak negative</li>
                        <li><strong>r = -0.4 to -0.6:</strong> Moderate negative</li>
                        <li><strong>r = -0.7 to -0.9:</strong> Strong negative</li>
                        <li><strong>r = -1:</strong> Perfect negative correlation</li>
                    </ul>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>Study hours vs exam scores typically show r = 0.7 (strong positive). More study hours correlate with higher scores.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>r ranges from -1 to +1</li>
                        <li>Measures strength AND direction of linear relationship</li>
                        <li>Scale-independent (unlike covariance)</li>
                        <li>Only measures LINEAR relationships</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 13: Interpreting Correlation -->
            <section class="topic-section" id="topic-13">
                <div class="topic-header">
                    <span class="topic-number">Topic 13</span>
                    <h2>💪 Interpreting Correlation</h2>
                    <p class="topic-subtitle">Correlation vs causation and common pitfalls</p>
                </div>

                <div class="content-card">
                    <h3>The Golden Rule</h3>
                    <div class="callout-box warning">
                        <div class="callout-header">⚠️ CORRELATION ≠ CAUSATION</div>
                        <p>Just because two variables are correlated does NOT mean one causes the other!</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Common Scenarios</h3>
                    <ul>
                        <li><strong>Direct Causation:</strong> X causes Y (smoking causes cancer)</li>
                        <li><strong>Reverse Causation:</strong> Y causes X (not the direction you thought)</li>
                        <li><strong>Third Variable:</strong> Z causes both X and Y (confounding variable)</li>
                        <li><strong>Coincidence:</strong> Pure chance with no real relationship</li>
                    </ul>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 FAMOUS EXAMPLE</div>
                    <p><strong>Ice cream sales correlate with drowning deaths.</strong></p>
                    <p>Does ice cream cause drowning? NO! The third variable is summer weather—more people swim in summer (more drownings) and eat ice cream in summer.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Correlation shows relationship, NOT causation</li>
                        <li>Always consider third variables (confounders)</li>
                        <li>Need controlled experiments to prove causation</li>
                        <li>Be skeptical of correlation claims in media</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 14: Probability Basics -->
            <section class="topic-section" id="topic-14">
                <div class="topic-header">
                    <span class="topic-number">Topic 14</span>
                    <h2>🎲 Probability Basics</h2>
                    <p class="topic-subtitle">Foundation of statistical inference</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Probability measures the likelihood of an event occurring, ranging from 0 (impossible) to 1 (certain).</p>
                    <p><strong>Why it matters:</strong> Foundation for all statistical inference, hypothesis testing, and prediction.</p>
                </div>

                <div class="content-card">
                    <h3>Basic Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Probability of Event E</div>
                        <div class="formula-main">P(E) = Number of favorable outcomes / Total number of possible outcomes</div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Key Rules</h3>
                    <ul>
                        <li><strong>Range:</strong> 0 ≤ P(E) ≤ 1</li>
                        <li><strong>Complement:</strong> P(not E) = 1 - P(E)</li>
                        <li><strong>Addition (OR):</strong> P(A or B) = P(A) + P(B) - P(A and B)</li>
                        <li><strong>Multiplication (AND):</strong> P(A and B) = P(A) × P(B) [if independent]</li>
                    </ul>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>Rolling a die:</strong></p>
                    <p>P(rolling a 4) = 1/6 ≈ 0.167</p>
                    <p>P(rolling even) = 3/6 = 0.5</p>
                    <p>P(not rolling a 6) = 5/6 ≈ 0.833</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Probability ranges from 0 to 1</li>
                        <li>P(E) = favorable outcomes / total outcomes</li>
                        <li>Complement rule: P(not E) = 1 - P(E)</li>
                        <li>Foundation for all statistical inference</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 15: Set Theory -->
            <section class="topic-section" id="topic-15">
                <div class="topic-header">
                    <span class="topic-number">Topic 15</span>
                    <h2>🔷 Set Theory</h2>
                    <p class="topic-subtitle">Union, intersection, and complement</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Set theory provides a mathematical framework for organizing events and calculating probabilities.</p>
                </div>

                <div class="content-card">
                    <h3>Key Concepts</h3>
                    <ul>
                        <li><strong>Union (A ∪ B):</strong> A OR B (either event occurs)</li>
                        <li><strong>Intersection (A ∩ B):</strong> A AND B (both events occur)</li>
                        <li><strong>Complement (A'):</strong> NOT A (event doesn't occur)</li>
                        <li><strong>Mutually Exclusive:</strong> A ∩ B = ∅ (can't both occur)</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Union (∪): OR operation</li>
                        <li>Intersection (∩): AND operation</li>
                        <li>Complement ('): NOT operation</li>
                        <li>Venn diagrams visualize set relationships</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 16: Conditional Probability -->
            <section class="topic-section" id="topic-16">
                <div class="topic-header">
                    <span class="topic-number">Topic 16</span>
                    <h2>🔀 Conditional Probability</h2>
                    <p class="topic-subtitle">Probability given that something else happened</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Conditional probability is the probability of event A occurring given that event B has already occurred.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Conditional Probability</div>
                        <div class="formula-main">P(A|B) = P(A and B) / P(B)</div>
                        <p>Read as: "Probability of A given B"</p>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p>Drawing cards: P(King | Red card) = ?</p>
                    <p>P(Red card) = 26/52</p>
                    <p>P(King and Red) = 2/52</p>
                    <p>P(King | Red) = (2/52) / (26/52) = 2/26 = 1/13</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>P(A|B) = probability of A given B occurred</li>
                        <li>Formula: P(A|B) = P(A and B) / P(B)</li>
                        <li>Critical for Bayes' Theorem</li>
                        <li>Used in machine learning and diagnostics</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 17: Independence -->
            <section class="topic-section" id="topic-17">
                <div class="topic-header">
                    <span class="topic-number">Topic 17</span>
                    <h2>🎯 Independence</h2>
                    <p class="topic-subtitle">When events don't affect each other</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Two events are independent if the occurrence of one doesn't affect the probability of the other.</p>
                </div>

                <div class="content-card">
                    <h3>Test for Independence</h3>
                    <div class="formula-card">
                        <div class="formula-header">Events A and B are independent if:</div>
                        <div class="formula-main">P(A|B) = P(A)</div>
                        <p>OR equivalently:</p>
                        <div class="formula-main">P(A and B) = P(A) × P(B)</div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Examples</h3>
                    <ul>
                        <li><strong>Independent:</strong> Coin flips, die rolls with replacement</li>
                        <li><strong>Dependent:</strong> Drawing cards without replacement, weather on consecutive days</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Independent events don't affect each other</li>
                        <li>Test: P(A and B) = P(A) × P(B)</li>
                        <li>With replacement → independent</li>
                        <li>Without replacement → dependent</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 18: Bayes' Theorem -->
            <section class="topic-section" id="topic-18">
                <div class="topic-header">
                    <span class="topic-number">Topic 18</span>
                    <h2>🧮 Bayes' Theorem</h2>
                    <p class="topic-subtitle">Updating probabilities with new evidence</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Bayes' Theorem shows how to update probability based on new information.</p>
                    <p><strong>Why it matters:</strong> Used in medical diagnosis, spam filters, machine learning, and countless applications.</p>
                </div>

                <div class="content-card">
                    <h3>The Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Bayes' Theorem</div>
                        <div class="formula-main">P(A|B) = [P(B|A) × P(A)] / P(B)</div>
                        <ul>
                            <li>P(A|B) = posterior probability</li>
                            <li>P(B|A) = likelihood</li>
                            <li>P(A) = prior probability</li>
                            <li>P(B) = marginal probability</li>
                        </ul>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 MEDICAL DIAGNOSIS EXAMPLE</div>
                    <p><strong>Disease affects 1% of population. Test is 95% accurate.</strong></p>
                    <p>You test positive. What's probability you have disease?</p>
                    <div class="example-solution">
                        <p>P(Disease) = 0.01</p>
                        <p>P(Positive|Disease) = 0.95</p>
                        <p>P(Positive|No Disease) = 0.05</p>
                        <p>P(Positive) = 0.01×0.95 + 0.99×0.05 = 0.059</p>
                        <p>P(Disease|Positive) = (0.95×0.01)/0.059 = 0.161</p>
                        <p><strong>Only 16.1% chance you have the disease!</strong></p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Updates probability based on new evidence</li>
                        <li>P(A|B) = [P(B|A) × P(A)] / P(B)</li>
                        <li>Critical for medical testing and machine learning</li>
                        <li>Counter-intuitive results common (base rate matters!)</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 19: PMF -->
            <section class="topic-section" id="topic-19">
                <div class="topic-header">
                    <span class="topic-number">Topic 19</span>
                    <h2>📊 Probability Mass Function (PMF)</h2>
                    <p class="topic-subtitle">Probabilities for discrete random variables</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> PMF gives the probability that a discrete random variable equals a specific value.</p>
                    <p><strong>Why it matters:</strong> Used for countable outcomes like dice rolls, coin flips, or number of defects.</p>
                </div>

                <div class="content-card">
                    <h3>Properties</h3>
                    <ul>
                        <li>0 ≤ P(X = x) ≤ 1 for all x</li>
                        <li>Sum of all probabilities = 1</li>
                        <li>Only defined for discrete variables</li>
                        <li>Visualized with bar charts</li>
                    </ul>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE: Die Roll</div>
                    <p>P(X = 1) = 1/6</p>
                    <p>P(X = 2) = 1/6</p>
                    <p>... and so on</p>
                    <p>Sum = 6 × (1/6) = 1 ✓</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>PMF is for discrete random variables</li>
                        <li>Gives P(X = specific value)</li>
                        <li>All probabilities sum to 1</li>
                        <li>Visualized with bar charts</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 20: PDF -->
            <section class="topic-section" id="topic-20">
                <div class="topic-header">
                    <span class="topic-number">Topic 20</span>
                    <h2>📈 Probability Density Function (PDF)</h2>
                    <p class="topic-subtitle">Probabilities for continuous random variables</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> PDF describes probability for continuous random variables. Probability at exact point is 0; we calculate probability over intervals.</p>
                </div>

                <div class="content-card">
                    <h3>Key Differences from PMF</h3>
                    <ul>
                        <li>For continuous (not discrete) variables</li>
                        <li>P(X = exact value) = 0</li>
                        <li>Calculate P(a &lt; X &lt; b) = area under curve</li>
                        <li>Total area under curve = 1</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>PDF is for continuous random variables</li>
                        <li>Probability = area under curve</li>
                        <li>P(X = exact point) = 0</li>
                        <li>Total area under PDF = 1</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 21: CDF -->
            <section class="topic-section" id="topic-21">
                <div class="topic-header">
                    <span class="topic-number">Topic 21</span>
                    <h2>📉 Cumulative Distribution Function (CDF)</h2>
                    <p class="topic-subtitle">Probability up to a value</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> CDF gives the probability that X is less than or equal to a specific value.</p>
                    <p><strong>Formula:</strong> F(x) = P(X ≤ x)</p>
                </div>

                <div class="content-card">
                    <h3>Properties</h3>
                    <ul>
                        <li>Always non-decreasing</li>
                        <li>F(-∞) = 0</li>
                        <li>F(+∞) = 1</li>
                        <li>P(a &lt; X ≤ b) = F(b) - F(a)</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>CDF: F(x) = P(X ≤ x)</li>
                        <li>Works for both discrete and continuous</li>
                        <li>Always increases from 0 to 1</li>
                        <li>Useful for finding percentiles</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 22: Bernoulli Distribution -->
            <section class="topic-section" id="topic-22">
                <div class="topic-header">
                    <span class="topic-number">Topic 22</span>
                    <h2>🪙 Bernoulli Distribution</h2>
                    <p class="topic-subtitle">Single trial with two outcomes</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Models a single trial with two outcomes: success (1) or failure (0).</p>
                    <p><strong>Examples:</strong> Coin flip, pass/fail test, yes/no question</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Bernoulli PMF</div>
                        <div class="formula-main">P(X = 1) = p</div>
                        <div class="formula-main">P(X = 0) = 1 - p = q</div>
                        <p>Mean = p, Variance = p(1-p)</p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Single trial, two outcomes (0 or 1)</li>
                        <li>Parameter: p (probability of success)</li>
                        <li>Mean = p, Variance = p(1-p)</li>
                        <li>Building block for binomial distribution</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 23: Binomial Distribution -->
            <section class="topic-section" id="topic-23">
                <div class="topic-header">
                    <span class="topic-number">Topic 23</span>
                    <h2>🎰 Binomial Distribution</h2>
                    <p class="topic-subtitle">Multiple independent Bernoulli trials</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Models the number of successes in n independent Bernoulli trials.</p>
                    <p><strong>Requirements:</strong> Fixed n, same p, independent trials, binary outcomes</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Binomial PMF</div>
                        <div class="formula-main">P(X = k) = C(n,k) × p^k × (1-p)^(n-k)</div>
                        <p>C(n,k) = n! / (k!(n-k)!)</p>
                        <p>Mean = np, Variance = np(1-p)</p>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p>Flip coin 10 times. P(exactly 6 heads)?</p>
                    <p>n=10, k=6, p=0.5</p>
                    <p>P(X=6) = C(10,6) × 0.5^6 × 0.5^4 = 210 × 0.000977 ≈ 0.205</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>n independent trials, probability p each</li>
                        <li>Counts number of successes</li>
                        <li>Mean = np, Variance = np(1-p)</li>
                        <li>Common in quality control and surveys</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 24: Normal Distribution -->
            <section class="topic-section" id="topic-24">
                <div class="topic-header">
                    <span class="topic-number">Topic 24</span>
                    <h2>🔔 Normal Distribution</h2>
                    <p class="topic-subtitle">The bell curve and 68-95-99.7 rule</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The most important continuous probability distribution—symmetric, bell-shaped curve.</p>
                    <p><strong>Why it matters:</strong> Many natural phenomena follow normal distribution. Foundation of inferential statistics.</p>
                </div>

                <div class="content-card">
                    <h3>Properties</h3>
                    <ul>
                        <li>Symmetric around mean μ</li>
                        <li>Bell-shaped curve</li>
                        <li>Mean = Median = Mode</li>
                        <li>Defined by μ (mean) and σ (standard deviation)</li>
                        <li>Total area under curve = 1</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>The 68-95-99.7 Rule (Empirical Rule)</h3>
                    <ul>
                        <li><strong>68%</strong> of data within μ ± 1σ</li>
                        <li><strong>95%</strong> of data within μ ± 2σ</li>
                        <li><strong>99.7%</strong> of data within μ ± 3σ</li>
                    </ul>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>IQ scores: μ = 100, σ = 15</p>
                    <p>68% of people have IQ between 85-115</p>
                    <p>95% have IQ between 70-130</p>
                    <p>99.7% have IQ between 55-145</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Symmetric bell curve, parameters μ and σ</li>
                        <li>68-95-99.7 rule for standard deviations</li>
                        <li>Foundation for hypothesis testing</li>
                        <li>Central Limit Theorem connects to sampling</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 25: Hypothesis Testing Intro -->
            <section class="topic-section" id="topic-25">
                <div class="topic-header">
                    <span class="topic-number">Topic 25</span>
                    <h2>⚖️ Hypothesis Testing Introduction</h2>
                    <p class="topic-subtitle">Making decisions from data</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Statistical method for testing claims about populations using sample data.</p>
                    <p><strong>Why it matters:</strong> Allows us to make evidence-based decisions and determine if effects are real or due to chance.</p>
                </div>

                <div class="content-card">
                    <h3>The Two Hypotheses</h3>
                    <ul>
                        <li><strong>Null Hypothesis (H₀):</strong> Status quo, no effect, no difference</li>
                        <li><strong>Alternative Hypothesis (H₁ or Hₐ):</strong> What we're trying to prove</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Decision Process</h3>
                    <ol>
                        <li>State hypotheses (H₀ and H₁)</li>
                        <li>Choose significance level (α)</li>
                        <li>Collect data and calculate test statistic</li>
                        <li>Find p-value or critical value</li>
                        <li>Make decision: Reject H₀ or Fail to reject H₀</li>
                    </ol>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>Claim:</strong> New teaching method improves test scores</p>
                    <p>H₀: μ = 75 (no improvement)</p>
                    <p>H₁: μ &gt; 75 (scores improved)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>H₀ = null hypothesis (status quo)</li>
                        <li>H₁ = alternative hypothesis (what we test)</li>
                        <li>We either reject or fail to reject H₀</li>
                        <li>Never "accept" or "prove" anything</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 26: Significance Level α -->
            <section class="topic-section" id="topic-26">
                <div class="topic-header">
                    <span class="topic-number">Topic 26</span>
                    <h2>🎯 Significance Level (α)</h2>
                    <p class="topic-subtitle">Setting your error tolerance</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> α (alpha) is the probability of rejecting H₀ when it's actually true (Type I error rate).</p>
                    <p><strong>Common values:</strong> 0.05 (5%), 0.01 (1%), 0.10 (10%)</p>
                </div>

                <div class="content-card">
                    <h3>Interpretation</h3>
                    <ul>
                        <li><strong>α = 0.05:</strong> Willing to be wrong 5% of the time</li>
                        <li><strong>Lower α:</strong> More stringent, harder to reject H₀</li>
                        <li><strong>Higher α:</strong> More lenient, easier to reject H₀</li>
                        <li><strong>Confidence level:</strong> 1 - α (e.g., 0.05 → 95% confidence)</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>α = probability of Type I error</li>
                        <li>Common: α = 0.05 (5% error rate)</li>
                        <li>Set before collecting data</li>
                        <li>Trade-off between Type I and Type II errors</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 27: Standard Error -->
            <section class="topic-section" id="topic-27">
                <div class="topic-header">
                    <span class="topic-number">Topic 27</span>
                    <h2>📊 Standard Error</h2>
                    <p class="topic-subtitle">Measuring sampling variability</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Standard error (SE) measures how much sample means vary from the true population mean.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Standard Error of Mean</div>
                        <div class="formula-main">SE = σ / √n</div>
                        <p>or estimate: SE = s / √n</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Key Points</h3>
                    <ul>
                        <li>Decreases as sample size increases</li>
                        <li>Measures precision of sample mean</li>
                        <li>Lower SE = better estimate</li>
                        <li>Used in confidence intervals and hypothesis tests</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>SE = σ / √n</li>
                        <li>Measures sampling variability</li>
                        <li>Larger samples → smaller SE</li>
                        <li>Critical for inference</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 28: Z-Test -->
            <section class="topic-section" id="topic-28">
                <div class="topic-header">
                    <span class="topic-number">Topic 28</span>
                    <h2>📏 Z-Test</h2>
                    <p class="topic-subtitle">Hypothesis test for large samples with known σ</p>
                </div>

                <div class="content-card">
                    <h3>When to Use Z-Test</h3>
                    <ul>
                        <li>Sample size n ≥ 30 (large sample)</li>
                        <li>Population standard deviation (σ) known</li>
                        <li>Testing population mean</li>
                        <li>Normal distribution or large n</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Z-Test Statistic</div>
                        <div class="formula-main">z = (x̄ - μ₀) / (σ / √n)</div>
                        <p>x̄ = sample mean</p>
                        <p>μ₀ = hypothesized population mean</p>
                        <p>σ = population standard deviation</p>
                        <p>n = sample size</p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Use when n ≥ 30 and σ known</li>
                        <li>z = (x̄ - μ₀) / SE</li>
                        <li>Compare z to critical value or find p-value</li>
                        <li>Large |z| = evidence against H₀</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 29: Z-Score & Critical Values -->
            <section class="topic-section" id="topic-29">
                <div class="topic-header">
                    <span class="topic-number">Topic 29</span>
                    <h2>🎚️ Z-Score &amp; Critical Values</h2>
                    <p class="topic-subtitle">Standardization and rejection regions</p>
                </div>

                <div class="content-card">
                    <h3>Z-Score (Standardization)</h3>
                    <div class="formula-card">
                        <div class="formula-header">Z-Score Formula</div>
                        <div class="formula-main">z = (x - μ) / σ</div>
                        <p>Converts any normal distribution to standard normal (μ=0, σ=1)</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Critical Values</h3>
                    <ul>
                        <li><strong>α = 0.05 (two-tailed):</strong> z = ±1.96</li>
                        <li><strong>α = 0.05 (one-tailed):</strong> z = 1.645</li>
                        <li><strong>α = 0.01 (two-tailed):</strong> z = ±2.576</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Z-score standardizes values</li>
                        <li>Critical values define rejection region</li>
                        <li>|z| &gt; critical value → reject H₀</li>
                        <li>Common: ±1.96 for 95% confidence</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 30: P-Value -->
            <section class="topic-section" id="topic-30">
                <div class="topic-header">
                    <span class="topic-number">Topic 30</span>
                    <h2>💯 P-Value Method</h2>
                    <p class="topic-subtitle">Probability of observing data if H₀ is true</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> P-value is the probability of getting results as extreme as observed, assuming H₀ is true.</p>
                </div>

                <div class="content-card">
                    <h3>Decision Rule</h3>
                    <ul>
                        <li><strong>If p-value ≤ α:</strong> Reject H₀ (statistically significant)</li>
                        <li><strong>If p-value &gt; α:</strong> Fail to reject H₀ (not significant)</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Interpretation</h3>
                    <ul>
                        <li><strong>p &lt; 0.01:</strong> Very strong evidence against H₀</li>
                        <li><strong>0.01 ≤ p &lt; 0.05:</strong> Strong evidence against H₀</li>
                        <li><strong>0.05 ≤ p &lt; 0.10:</strong> Weak evidence against H₀</li>
                        <li><strong>p ≥ 0.10:</strong> Little or no evidence against H₀</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISCONCEPTION</div>
                    <p>P-value is NOT the probability that H₀ is true! It's the probability of observing your data IF H₀ were true.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>P-value = P(data | H₀ true)</li>
                        <li>Reject H₀ if p ≤ α</li>
                        <li>Smaller p-value = stronger evidence against H₀</li>
                        <li>Most common approach in modern statistics</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 31: One vs Two Tailed -->
            <section class="topic-section" id="topic-31">
                <div class="topic-header">
                    <span class="topic-number">Topic 31</span>
                    <h2>↔️ One-Tailed vs Two-Tailed Tests</h2>
                    <p class="topic-subtitle">Directional vs non-directional hypotheses</p>
                </div>

                <div class="content-card">
                    <h3>Two-Tailed Test</h3>
                    <ul>
                        <li><strong>H₁:</strong> μ ≠ μ₀ (different, could be higher or lower)</li>
                        <li>Testing for any difference</li>
                        <li>Rejection regions in both tails</li>
                        <li>More conservative</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>One-Tailed Test</h3>
                    <ul>
                        <li><strong>Right-tailed:</strong> H₁: μ &gt; μ₀</li>
                        <li><strong>Left-tailed:</strong> H₁: μ &lt; μ₀</li>
                        <li>Testing for specific direction</li>
                        <li>Rejection region in one tail</li>
                        <li>More powerful for directional effects</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Two-tailed: testing for any difference</li>
                        <li>One-tailed: testing for specific direction</li>
                        <li>Choose before collecting data</li>
                        <li>Two-tailed is more conservative</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 32: T-Test -->
            <section class="topic-section" id="topic-32">
                <div class="topic-header">
                    <span class="topic-number">Topic 32</span>
                    <h2>📐 T-Test</h2>
                    <p class="topic-subtitle">Hypothesis test for small samples or unknown σ</p>
                </div>

                <div class="content-card">
                    <h3>When to Use T-Test</h3>
                    <ul>
                        <li>Small sample (n &lt; 30)</li>
                        <li>Population σ unknown (use sample s)</li>
                        <li>Population approximately normal</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">T-Test Statistic</div>
                        <div class="formula-main">t = (x̄ - μ₀) / (s / √n)</div>
                        <p>Same as z-test but uses s instead of σ</p>
                        <p>Follows t-distribution with df = n - 1</p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Use when σ unknown or n &lt; 30</li>
                        <li>t = (x̄ - μ₀) / (s / √n)</li>
                        <li>Follows t-distribution</li>
                        <li>More variable than z-distribution</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 33: Degrees of Freedom -->
            <section class="topic-section" id="topic-33">
                <div class="topic-header">
                    <span class="topic-number">Topic 33</span>
                    <h2>🔓 Degrees of Freedom</h2>
                    <p class="topic-subtitle">Independent pieces of information</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Degrees of freedom (df) is the number of independent values that can vary in analysis.</p>
                </div>

                <div class="content-card">
                    <h3>Common Formulas</h3>
                    <ul>
                        <li><strong>One-sample t-test:</strong> df = n - 1</li>
                        <li><strong>Two-sample t-test:</strong> df ≈ n₁ + n₂ - 2</li>
                        <li><strong>Chi-squared:</strong> df = (rows-1)(cols-1)</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Why It Matters</h3>
                    <ul>
                        <li>Determines shape of t-distribution</li>
                        <li>Higher df → closer to normal distribution</li>
                        <li>Affects critical values</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>df = number of independent values</li>
                        <li>For t-test: df = n - 1</li>
                        <li>Higher df → distribution closer to normal</li>
                        <li>Critical for finding correct critical values</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 34: Type I & II Errors -->
            <section class="topic-section" id="topic-34">
                <div class="topic-header">
                    <span class="topic-number">Topic 34</span>
                    <h2>⚠️ Type I &amp; Type II Errors</h2>
                    <p class="topic-subtitle">False positives and false negatives</p>
                </div>

                <div class="content-card">
                    <h3>The Two Types of Errors</h3>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th></th>
                                <th>H₀ True</th>
                                <th>H₀ False</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Reject H₀</strong></td>
                                <td style="color: #ff6b6b;">Type I Error (α)</td>
                                <td style="color: #51cf66;">Correct!</td>
                            </tr>
                            <tr>
                                <td><strong>Fail to Reject H₀</strong></td>
                                <td style="color: #51cf66;">Correct!</td>
                                <td style="color: #ff6b6b;">Type II Error (β)</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="content-card">
                    <h3>Definitions</h3>
                    <ul>
                        <li><strong>Type I Error (α):</strong> Rejecting true H₀ (false positive)</li>
                        <li><strong>Type II Error (β):</strong> Failing to reject false H₀ (false negative)</li>
                        <li><strong>Power = 1 - β:</strong> Probability of correctly rejecting false H₀</li>
                    </ul>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 MEDICAL ANALOGY</div>
                    <p><strong>Type I Error:</strong> Telling healthy person they're sick (false alarm)</p>
                    <p><strong>Type II Error:</strong> Telling sick person they're healthy (missed diagnosis)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Type I: False positive (α)</li>
                        <li>Type II: False negative (β)</li>
                        <li>Trade-off: decreasing one increases the other</li>
                        <li>Power = 1 - β (ability to detect true effect)</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 35: Chi-Squared Distribution -->
            <section class="topic-section" id="topic-35">
                <div class="topic-header">
                    <span class="topic-number">Topic 35</span>
                    <h2>χ² Chi-Squared Distribution</h2>
                    <p class="topic-subtitle">Distribution for categorical data analysis</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Chi-squared (χ²) distribution is used for testing hypotheses about categorical data.</p>
                </div>

                <div class="content-card">
                    <h3>Properties</h3>
                    <ul>
                        <li>Always positive (ranges from 0 to ∞)</li>
                        <li>Right-skewed</li>
                        <li>Shape depends on degrees of freedom</li>
                        <li>Higher df → more symmetric</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Uses</h3>
                    <ul>
                        <li>Goodness of fit test</li>
                        <li>Test of independence</li>
                        <li>Testing variance</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Used for categorical data</li>
                        <li>Always positive, right-skewed</li>
                        <li>Shape depends on df</li>
                        <li>Foundation for chi-squared tests</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 36: Goodness of Fit -->
            <section class="topic-section" id="topic-36">
                <div class="topic-header">
                    <span class="topic-number">Topic 36</span>
                    <h2>✓ Goodness of Fit Test</h2>
                    <p class="topic-subtitle">Testing if data follows expected distribution</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Tests whether observed frequencies match expected frequencies from a theoretical distribution.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Chi-Squared Test Statistic</div>
                        <div class="formula-main">χ² = Σ [(O - E)² / E]</div>
                        <p>O = observed frequency</p>
                        <p>E = expected frequency</p>
                        <p>df = k - 1 (k = number of categories)</p>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>Testing if die is fair:</strong></p>
                    <p>Roll 60 times. Expected: 10 per face</p>
                    <p>Observed: 8, 12, 11, 9, 10, 10</p>
                    <p>Calculate χ² and compare to critical value</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Tests if observed matches expected distribution</li>
                        <li>χ² = Σ(O-E)²/E</li>
                        <li>Large χ² = poor fit</li>
                        <li>df = number of categories - 1</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 37: Test of Independence -->
            <section class="topic-section" id="topic-37">
                <div class="topic-header">
                    <span class="topic-number">Topic 37</span>
                    <h2>🔗 Test of Independence</h2>
                    <p class="topic-subtitle">Testing relationship between categorical variables</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Tests whether two categorical variables are independent or associated.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Chi-Squared for Independence</div>
                        <div class="formula-main">χ² = Σ [(O - E)² / E]</div>
                        <p>E = (row total × column total) / grand total</p>
                        <p>df = (rows - 1)(columns - 1)</p>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>Are gender and color preference independent?</strong></p>
                    <p>Create contingency table, calculate expected frequencies, compute χ², and test against critical value.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Tests independence of two categorical variables</li>
                        <li>Uses contingency tables</li>
                        <li>df = (r-1)(c-1)</li>
                        <li>Large χ² suggests association</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 38: Chi-Squared for Variance -->
            <section class="topic-section" id="topic-38">
                <div class="topic-header">
                    <span class="topic-number">Topic 38</span>
                    <h2>📏 Chi-Squared Variance Test</h2>
                    <p class="topic-subtitle">Testing claims about population variance</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Tests hypotheses about population variance or standard deviation.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Chi-Squared for Variance</div>
                        <div class="formula-main">χ² = (n-1)s² / σ₀²</div>
                        <p>n = sample size</p>
                        <p>s² = sample variance</p>
                        <p>σ₀² = hypothesized population variance</p>
                        <p>df = n - 1</p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Tests claims about variance/standard deviation</li>
                        <li>χ² = (n-1)s²/σ₀²</li>
                        <li>Requires normal population</li>
                        <li>Common in quality control</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 39: Confidence Intervals -->
            <section class="topic-section" id="topic-39">
                <div class="topic-header">
                    <span class="topic-number">Topic 39</span>
                    <h2>📊 Confidence Intervals</h2>
                    <p class="topic-subtitle">Range of plausible values for parameter</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A confidence interval provides a range of values that likely contains the true population parameter.</p>
                    <p><strong>Why it matters:</strong> More informative than point estimates—shows precision and uncertainty.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Confidence Interval for Mean</div>
                        <div class="formula-main">CI = x̄ ± (critical value × SE)</div>
                        <p>For z: CI = x̄ ± z* × (σ/√n)</p>
                        <p>For t: CI = x̄ ± t* × (s/√n)</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Common Confidence Levels</h3>
                    <ul>
                        <li><strong>90% CI:</strong> z* = 1.645</li>
                        <li><strong>95% CI:</strong> z* = 1.96</li>
                        <li><strong>99% CI:</strong> z* = 2.576</li>
                    </ul>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p>Sample: n=100, x̄=50, s=10</p>
                    <p>95% CI = 50 ± 1.96(10/√100)</p>
                    <p>95% CI = 50 ± 1.96 = (48.04, 51.96)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>CI = point estimate ± margin of error</li>
                        <li>95% CI most common</li>
                        <li>Wider CI = more uncertainty</li>
                        <li>Larger sample = narrower CI</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 40: Margin of Error -->
            <section class="topic-section" id="topic-40">
                <div class="topic-header">
                    <span class="topic-number">Topic 40</span>
                    <h2>± Margin of Error</h2>
                    <p class="topic-subtitle">Measuring estimate precision</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Margin of error (MOE) is the ± part of a confidence interval, showing the precision of an estimate.</p>
                </div>

                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Margin of Error</div>
                        <div class="formula-main">MOE = (critical value) × SE</div>
                        <p>MOE = z* × (σ/√n) or t* × (s/√n)</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Factors Affecting MOE</h3>
                    <ul>
                        <li><strong>Sample size:</strong> Larger n → smaller MOE</li>
                        <li><strong>Confidence level:</strong> Higher confidence → larger MOE</li>
                        <li><strong>Variability:</strong> Higher σ → larger MOE</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>MOE = critical value × SE</li>
                        <li>Indicates precision of estimate</li>
                        <li>Inversely related to sample size</li>
                        <li>Trade-off between confidence and precision</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 41: Interpreting CIs -->
            <section class="topic-section" id="topic-41">
                <div class="topic-header">
                    <span class="topic-number">Topic 41</span>
                    <h2>🔍 Interpreting Confidence Intervals</h2>
                    <p class="topic-subtitle">Common misconceptions and proper interpretation</p>
                </div>

                <div class="content-card">
                    <h3>Correct Interpretation</h3>
                    <p><strong>"We are 95% confident that the true population parameter lies within this interval."</strong></p>
                    <p>This means: If we repeated this process many times, 95% of the intervals would contain the true parameter.</p>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISCONCEPTIONS</div>
                    <ul>
                        <li><strong>WRONG:</strong> "There's a 95% probability the parameter is in this interval."</li>
                        <li><strong>WRONG:</strong> "95% of the data falls in this interval."</li>
                        <li><strong>WRONG:</strong> "We are 95% sure our sample mean is in this interval."</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Using CIs for Hypothesis Testing</h3>
                    <ul>
                        <li>If hypothesized value is INSIDE CI → fail to reject H₀</li>
                        <li>If hypothesized value is OUTSIDE CI → reject H₀</li>
                        <li>95% CI corresponds to α = 0.05 test</li>
                    </ul>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIP</div>
                    <p>Report confidence intervals instead of just p-values! CIs provide more information: effect size AND statistical significance.</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Correct interpretation: confidence in the method, not the specific interval</li>
                        <li>95% refers to long-run success rate</li>
                        <li>Can use CIs for hypothesis testing</li>
                        <li>More informative than p-values alone</li>
                    </ul>
                </div>
            </section>

            <!-- LINEAR ALGEBRA TOPICS (42-57) -->

            <!-- Topic 42: Vectors -->
            <section class="topic-section" id="topic-42" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 42</span>
                    <h2>➡️ Vectors - What Even Are They?</h2>
                    <p class="topic-subtitle">Multiple perspectives on vectors: physics, CS, and mathematics</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A vector can be viewed from three perspectives: as an arrow in space (physics), as an ordered list of numbers (computer science), or as an abstract object that can be added and scaled (mathematics).</p>
                    <p><strong>Why it matters:</strong> Vectors are fundamental to linear algebra, physics, machine learning, and computer graphics. Understanding vectors unlocks countless applications.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 THREE PERSPECTIVES</div>
                    <p><strong>Physics:</strong> Arrows with magnitude and direction (velocity, force)</p>
                    <p><strong>Computer Science:</strong> Ordered lists of numbers [3, 2] representing data</p>
                    <p><strong>Mathematics:</strong> Abstract objects following specific rules (addition, scaling)</p>
                </div>

                <div class="content-card">
                    <h3>Vector Operations</h3>
                    <div class="formula-card">
                        <div class="formula-header">Vector Notation</div>
                        <div class="formula-main">v = [x, y] in 2D<br>v = [x, y, z] in 3D</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Addition</div>
                        <div class="formula-main">v + w = [v₁ + w₁, v₂ + w₂]</div>
                        <p>Tip-to-tail method: Place vectors end-to-end</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Scalar Multiplication</div>
                        <div class="formula-main">cv = [cv₁, cv₂]</div>
                        <p>Stretches (c &gt; 1) or shrinks (0 &lt; c &lt; 1) the vector</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Interactive Vector Playground</h3>
                    <canvas id="canvas-42" width="600" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Vector X: <span id="vec42x">3</span></label>
                            <input type="range" id="slider42x" min="-5" max="5" value="3" step="0.5" class="slider">
                        </div>
                        <div class="slider-group">
                            <label>Vector Y: <span id="vec42y">2</span></label>
                            <input type="range" id="slider42y" min="-5" max="5" value="2" step="0.5" class="slider">
                        </div>
                        <button class="btn btn-primary" id="btn42reset">Reset</button>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Vectors have three valid perspectives: arrows, lists, abstract objects</li>
                        <li>Addition: tip-to-tail method geometrically</li>
                        <li>Scalar multiplication: stretching or shrinking</li>
                        <li>Foundation for all of linear algebra</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 43: Linear Combinations -->
            <section class="topic-section" id="topic-43" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 43</span>
                    <h2>🎯 Linear Combinations, Span, and Basis Vectors</h2>
                    <p class="topic-subtitle">Building all vectors from fundamental components</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Any vector can be expressed as a linear combination of basis vectors. In 2D, we use i-hat [1,0] and j-hat [0,1].</p>
                    <p><strong>The span</strong> of vectors is all possible linear combinations you can create by scaling and adding them.</p>
                </div>

                <div class="content-card">
                    <h3>Key Concepts</h3>
                    <div class="formula-card">
                        <div class="formula-header">Basis Vectors (2D)</div>
                        <div class="formula-main">î = [1, 0] &nbsp; ĵ = [0, 1]</div>
                        <p>Any vector v = [x, y] = x·î + y·ĵ</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Linear Combination</div>
                        <div class="formula-main">v = a·v₁ + b·v₂ + ... + c·vₙ</div>
                        <p>Where a, b, c are scalars</p>
                    </div>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 SPAN INTUITION</div>
                    <p><strong>1 vector:</strong> Span is a line through the origin</p>
                    <p><strong>2 non-parallel vectors:</strong> Span is the entire 2D plane</p>
                    <p><strong>2 parallel vectors:</strong> Span is still just a line</p>
                    <p><strong>Key:</strong> Linear independence determines the dimensionality of the span</p>
                </div>

                <div class="interactive-container">
                    <h3>Span Visualization</h3>
                    <canvas id="canvas-43" width="600" height="400"></canvas>
                    <div class="controls">
                        <button class="btn btn-primary" id="btn43animate">Animate Span</button>
                        <button class="btn btn-secondary" id="btn43reset">Reset</button>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Linear Independence</h3>
                    <p><strong>Independent:</strong> No vector can be expressed as a combination of others</p>
                    <p><strong>Dependent:</strong> At least one vector can be written as a combination of others</p>
                    <p><strong>Basis:</strong> A set of linearly independent vectors that span the entire space</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Linear combination: av + bw (scaling and adding)</li>
                        <li>Span: all possible linear combinations</li>
                        <li>Basis: minimal set of independent vectors spanning space</li>
                        <li>i-hat and j-hat are standard basis in 2D</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 44: Linear Transformations -->
            <section class="topic-section" id="topic-44" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 44</span>
                    <h2>🔄 Linear Transformations and Matrices</h2>
                    <p class="topic-subtitle">Matrices as movements of space</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A linear transformation moves vectors around space while keeping grid lines parallel and evenly spaced, with the origin fixed.</p>
                    <p><strong>Why matrices?</strong> A matrix completely describes a linear transformation by recording where the basis vectors land.</p>
                </div>

                <div class="content-card">
                    <h3>Properties of Linear Transformations</h3>
                    <div class="formula-card">
                        <div class="formula-header">Linearity Conditions</div>
                        <div class="formula-main">T(v + w) = T(v) + T(w)</div>
                        <div class="formula-main">T(cv) = c · T(v)</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Matrix Representation</div>
                        <div class="formula-main">A = [where î lands | where ĵ lands]</div>
                        <p>Columns are the transformed basis vectors</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Transformation Grid</h3>
                    <canvas id="canvas-44" width="600" height="400"></canvas>
                    <div class="controls">
                        <select id="select44" class="form-control">
                            <option value="identity">Identity</option>
                            <option value="rotation">Rotation 90°</option>
                            <option value="shear">Shear</option>
                            <option value="reflection">Reflection</option>
                        </select>
                        <button class="btn btn-primary" id="btn44apply">Apply Transform</button>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Linear transformations keep grid lines parallel</li>
                        <li>Matrix columns = where basis vectors land</li>
                        <li>Matrix-vector multiplication applies the transformation</li>
                        <li>Visual: watch the grid transform</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 54: Eigenvectors -->
            <section class="topic-section" id="topic-54" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 54</span>
                    <h2>🎯 Eigenvectors and Eigenvalues</h2>
                    <p class="topic-subtitle">Special vectors that only get scaled</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> An eigenvector of a matrix is a special vector that doesn't change direction during the transformation—it only gets scaled by its eigenvalue λ.</p>
                    <p><strong>Why it matters:</strong> Eigenvectors reveal the fundamental directions of a transformation. Used in Google PageRank, quantum mechanics, and data science.</p>
                </div>

                <div class="content-card">
                    <h3>The Eigenvalue Equation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Definition</div>
                        <div class="formula-main">Av = λv</div>
                        <p>A = matrix, v = eigenvector, λ = eigenvalue</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Finding Eigenvalues</div>
                        <div class="formula-main">det(A - λI) = 0</div>
                        <p>Characteristic equation: solve for λ</p>
                    </div>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 GEOMETRIC MEANING</div>
                    <p>Most vectors get knocked off their span during a transformation. But eigenvectors stay on their line—they just stretch or shrink!</p>
                    <p><strong>Example:</strong> A rotation has no real eigenvectors (everything rotates). A scaling transformation has eigenvectors along the axes.</p>
                </div>

                <div class="interactive-container">
                    <h3>Eigenvector Visualization</h3>
                    <canvas id="canvas-54" width="600" height="400"></canvas>
                    <div class="controls">
                        <button class="btn btn-primary" id="btn54transform">Apply Transformation</button>
                        <button class="btn btn-secondary" id="btn54reset">Reset</button>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Google PageRank:</strong> Finds important web pages using eigenvectors</li>
                        <li><strong>PCA (Principal Component Analysis):</strong> Data dimensionality reduction</li>
                        <li><strong>Stability Analysis:</strong> Engineering systems (will it oscillate or stabilize?)</li>
                        <li><strong>Quantum Mechanics:</strong> Energy states are eigenvectors</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Eigenvector: stays on its span, Av = λv</li>
                        <li>Eigenvalue λ: scaling factor</li>
                        <li>Find via det(A - λI) = 0</li>
                        <li>Reveal fundamental directions of transformation</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 45: Matrix Multiplication -->
            <section class="topic-section" id="topic-45" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 45</span>
                    <h2>🔗 Matrix Multiplication as Composition</h2>
                    <p class="topic-subtitle">Successive transformations</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Matrix multiplication represents applying one transformation after another (composition).</p>
                    <p><strong>Why it matters:</strong> Understanding this geometrically makes matrix multiplication intuitive instead of just memorizing rules.</p>
                </div>
                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Matrix Multiplication</div>
                        <div class="formula-main">(AB)v = A(Bv)</div>
                        <p>Apply B first, then A - right to left!</p>
                    </div>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Matrix multiplication = composition of transformations</li>
                        <li>Apply right-to-left: (AB)v means B first, then A</li>
                        <li>Generally not commutative: AB ≠ BA</li>
                        <li>Order matters!</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 46: 3D Transformations -->
            <section class="topic-section" id="topic-46" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 46</span>
                    <h2>🎲 3D Transformations</h2>
                    <p class="topic-subtitle">Extending to three dimensions</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Linear transformations in 3D space using 3×3 matrices.</p>
                    <p><strong>Why it matters:</strong> Essential for 3D graphics, robotics, and physics simulations.</p>
                </div>
                <div class="content-card">
                    <h3>Basis in 3D</h3>
                    <div class="formula-card">
                        <div class="formula-header">Standard Basis</div>
                        <div class="formula-main">î = [1, 0, 0]  ĵ = [0, 1, 0]  k̂ = [0, 0, 1]</div>
                        <p>3×3 matrix = [where î lands | where ĵ lands | where k̂ lands]</p>
                    </div>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>3D transformations use 3×3 matrices</li>
                        <li>Three basis vectors: î, ĵ, k̂</li>
                        <li>Used in computer graphics and physics</li>
                        <li>Same principles as 2D, extended to 3D</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 47: Determinant -->
            <section class="topic-section" id="topic-47" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 47</span>
                    <h2>📏 The Determinant</h2>
                    <p class="topic-subtitle">Measuring how transformations scale area/volume</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The determinant measures how much a transformation scales areas (2D) or volumes (3D).</p>
                    <p><strong>Why it matters:</strong> Tells if transformation is invertible, changes orientation, and by how much space is scaled.</p>
                </div>
                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">2×2 Determinant</div>
                        <div class="formula-main">det([a b; c d]) = ad - bc</div>
                    </div>
                </div>
                <div class="content-card">
                    <h3>Interpretation</h3>
                    <ul>
                        <li><strong>|det| &gt; 1:</strong> Expands space</li>
                        <li><strong>|det| &lt; 1:</strong> Compresses space</li>
                        <li><strong>det = 0:</strong> Squishes to lower dimension (not invertible)</li>
                        <li><strong>det &lt; 0:</strong> Flips orientation</li>
                    </ul>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Determinant = area/volume scaling factor</li>
                        <li>det = 0 means non-invertible (squishes space)</li>
                        <li>Negative det means orientation flip</li>
                        <li>Critical for understanding linear systems</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 48: Inverse Matrices -->
            <section class="topic-section" id="topic-48" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 48</span>
                    <h2>↩️ Inverse Matrices &amp; Column Space</h2>
                    <p class="topic-subtitle">Undoing transformations and solving systems</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The inverse matrix A⁻¹ undoes the transformation of A.</p>
                    <p><strong>Why it matters:</strong> Solving Ax = b means x = A⁻¹b (if inverse exists).</p>
                </div>
                <div class="content-card">
                    <h3>Key Concepts</h3>
                    <div class="formula-card">
                        <div class="formula-header">Inverse</div>
                        <div class="formula-main">AA⁻¹ = A⁻¹A = I</div>
                        <p>Exists only if det(A) ≠ 0</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Column Space</div>
                        <p>All possible outputs of Ax. The span of matrix columns.</p>
                    </div>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>A⁻¹ undoes transformation A</li>
                        <li>Exists only when det(A) ≠ 0</li>
                        <li>Column space = span of columns = range of transformation</li>
                        <li>Used to solve linear systems</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 49: Nonsquare Matrices -->
            <section class="topic-section" id="topic-49" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 49</span>
                    <h2>🔀 Nonsquare Matrices</h2>
                    <p class="topic-subtitle">Transformations between different dimensions</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> m×n matrices transform n-dimensional space to m-dimensional space.</p>
                    <p><strong>Why it matters:</strong> Many real-world problems involve different input/output dimensions.</p>
                </div>
                <div class="content-card">
                    <h3>Examples</h3>
                    <ul>
                        <li><strong>3×2 matrix:</strong> Maps 2D → 3D (embedding)</li>
                        <li><strong>2×3 matrix:</strong> Maps 3D → 2D (projection)</li>
                        <li><strong>Applications:</strong> Data compression, dimension reduction</li>
                    </ul>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>m×n matrices transform n-D to m-D</li>
                        <li>No inverse (can't undo dimension change perfectly)</li>
                        <li>Used in data science and machine learning</li>
                        <li>Columns still represent where basis vectors land</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 50: Dot Products -->
            <section class="topic-section" id="topic-50" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 50</span>
                    <h2>• Dot Products and Duality</h2>
                    <p class="topic-subtitle">Projection and measuring similarity</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The dot product v·w measures how much v and w point in the same direction.</p>
                </div>
                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Dot Product</div>
                        <div class="formula-main">v·w = v₁w₁ + v₂w₂ + ... + vₙwₙ</div>
                        <p>Also: v·w = |v||w|cos(θ)</p>
                    </div>
                </div>
                <div class="content-card">
                    <h3>Geometric Meaning</h3>
                    <ul>
                        <li><strong>v·w &gt; 0:</strong> Point in same direction</li>
                        <li><strong>v·w = 0:</strong> Perpendicular (orthogonal)</li>
                        <li><strong>v·w &lt; 0:</strong> Point in opposite directions</li>
                    </ul>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Dot product measures alignment/similarity</li>
                        <li>Zero dot product = perpendicular vectors</li>
                        <li>Used in projections and angle calculations</li>
                        <li>Foundation for inner product spaces</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 51: Cross Products -->
            <section class="topic-section" id="topic-51" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 51</span>
                    <h2>✖️ Cross Products</h2>
                    <p class="topic-subtitle">Finding perpendicular vectors in 3D</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The cross product v×w creates a vector perpendicular to both v and w.</p>
                    <p><strong>Why it matters:</strong> Essential in 3D physics (torque, angular momentum) and graphics.</p>
                </div>
                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Cross Product</div>
                        <div class="formula-main">v×w = [v₂w₃-v₃w₂, v₃w₁-v₁w₃, v₁w₂-v₂w₁]</div>
                        <p>Magnitude: |v×w| = |v||w|sin(θ)</p>
                    </div>
                </div>
                <div class="content-card">
                    <h3>Properties</h3>
                    <ul>
                        <li>Result perpendicular to both inputs</li>
                        <li>Magnitude = area of parallelogram</li>
                        <li>Direction: right-hand rule</li>
                        <li>Not commutative: v×w = -(w×v)</li>
                    </ul>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Cross product only defined in 3D</li>
                        <li>Result perpendicular to both vectors</li>
                        <li>Magnitude = area of parallelogram</li>
                        <li>Used in physics and computer graphics</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 52: Cross Products via Transformations -->
            <section class="topic-section" id="topic-52" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 52</span>
                    <h2>🔄 Cross Products via Transformations</h2>
                    <p class="topic-subtitle">Deeper understanding through linear transformations</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Understanding cross products through the lens of determinants and transformations.</p>
                    <p><strong>Why it matters:</strong> Reveals the connection between cross products, determinants, and volume.</p>
                </div>
                <div class="callout-box insight">
                    <div class="callout-header">💡 KEY INSIGHT</div>
                    <p>The cross product can be computed as the determinant of a special matrix involving basis vectors î, ĵ, k̂ and the components of v and w.</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Cross product related to determinant</li>
                        <li>Represents volume of parallelepiped</li>
                        <li>Geometric interpretation through transformations</li>
                        <li>Connects multiple LA concepts</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 53: Change of Basis -->
            <section class="topic-section" id="topic-53" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 53</span>
                    <h2>🔄 Change of Basis</h2>
                    <p class="topic-subtitle">Viewing the same transformation in different coordinate systems</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Converting between different coordinate systems (bases) to view transformations differently.</p>
                    <p><strong>Why it matters:</strong> Some problems are easier in different coordinate systems. Eigenvector basis simplifies many calculations.</p>
                </div>
                <div class="content-card">
                    <h3>The Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Change of Basis</div>
                        <div class="formula-main">A' = P⁻¹AP</div>
                        <p>P = change of basis matrix</p>
                        <p>A' = transformation in new basis</p>
                    </div>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Same transformation, different coordinate system</li>
                        <li>Formula: A' = P⁻¹AP</li>
                        <li>Eigenvector basis often simplest</li>
                        <li>Used in diagonalization</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 55: Eigenvalue Quick Trick -->
            <section class="topic-section" id="topic-55" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 55</span>
                    <h2>⚡ Eigenvalue Quick Trick</h2>
                    <p class="topic-subtitle">Fast methods for finding eigenvalues</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Shortcuts and tricks for quickly computing eigenvalues in special cases.</p>
                </div>
                <div class="content-card">
                    <h3>Quick Tricks</h3>
                    <ul>
                        <li><strong>Trace:</strong> Sum of eigenvalues = trace (sum of diagonal)</li>
                        <li><strong>Determinant:</strong> Product of eigenvalues = determinant</li>
                        <li><strong>Triangular matrices:</strong> Eigenvalues are diagonal entries</li>
                        <li><strong>2×2 matrices:</strong> Use trace and determinant directly</li>
                    </ul>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Trace = sum of eigenvalues</li>
                        <li>Determinant = product of eigenvalues</li>
                        <li>Diagonal/triangular: eigenvalues on diagonal</li>
                        <li>Saves computation time</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 56: Abstract Vector Spaces -->
            <section class="topic-section" id="topic-56" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 56</span>
                    <h2>∞ Abstract Vector Spaces</h2>
                    <p class="topic-subtitle">Beyond arrows and lists</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Vectors can be anything that follows vector space axioms: polynomials, functions, matrices themselves!</p>
                    <p><strong>Why it matters:</strong> Linear algebra applies to far more than just arrows in space.</p>
                </div>
                <div class="content-card">
                    <h3>Examples of Vector Spaces</h3>
                    <ul>
                        <li><strong>Polynomials:</strong> P(x) = a₀ + a₁x + a₂x² + ...</li>
                        <li><strong>Functions:</strong> f(x), g(x) can be added and scaled</li>
                        <li><strong>Matrices:</strong> Can add matrices and multiply by scalars</li>
                        <li><strong>Solutions to equations:</strong> Solution space forms vector space</li>
                    </ul>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Vector spaces: any set following vector axioms</li>
                        <li>Includes functions, polynomials, matrices</li>
                        <li>Same theorems apply to all vector spaces</li>
                        <li>Powerful abstraction in mathematics</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 57: Cramer's Rule -->
            <section class="topic-section" id="topic-57" data-subject="linear-algebra" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 57</span>
                    <h2>📐 Cramer's Rule</h2>
                    <p class="topic-subtitle">Solving systems using determinants</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A formula for solving linear systems Ax = b using determinants.</p>
                    <p><strong>Why it matters:</strong> Provides explicit formulas for solutions, though not always most efficient computationally.</p>
                </div>
                <div class="content-card">
                    <h3>Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Cramer's Rule</div>
                        <div class="formula-main">xᵢ = det(Aᵢ) / det(A)</div>
                        <p>Aᵢ = matrix A with column i replaced by b</p>
                    </div>
                </div>
                <div class="content-card">
                    <h3>Geometric Interpretation</h3>
                    <p>Solution relates to how much the output vector b changes the signed volume of the transformation.</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Solves Ax = b using determinants</li>
                        <li>xᵢ = det(Aᵢ) / det(A)</li>
                        <li>Works when det(A) ≠ 0</li>
                        <li>Elegant but not always efficient</li>
                    </ul>
                </div>
            </section>

            <!-- CALCULUS TOPICS -->

            <!-- Topic 58: Essence of Calculus -->
            <section class="topic-section" id="topic-58" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 58</span>
                    <h2>🎯 The Essence of Calculus</h2>
                    <p class="topic-subtitle">What calculus is really about</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Calculus is the mathematics of change and accumulation. It answers: "How fast?" (derivatives) and "How much total?" (integrals).</p>
                    <p><strong>Big Idea:</strong> Break problems into infinitely many infinitely small pieces, then add them up.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 THE CIRCLE AREA PROBLEM</div>
                    <p>How do we know the area of a circle is πr²?</p>
                    <p><strong>Calculus approach:</strong> Unwrap the circle into infinitely thin rings. Each ring is approximately a rectangle with height dr and width 2πr. Integrate from 0 to r:</p>
                    <p>∫ 2πr dr = πr²</p>
                    <p>This is the essence of integration: summing infinitely small pieces!</p>
                </div>

                <div class="interactive-container">
                    <h3>Circle Area Visualization</h3>
                    <canvas id="canvas-58" width="600" height="400"></canvas>
                    <div class="controls">
                        <button class="btn btn-primary" id="btn58animate">Unwrap Circle</button>
                        <button class="btn btn-secondary" id="btn58reset">Reset</button>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Two Fundamental Concepts</h3>
                    <div class="two-column">
                        <div class="column">
                            <h4 style="color: #64ffda;">Derivatives</h4>
                            <p>Instantaneous rate of change</p>
                            <p>Slope of tangent line</p>
                            <p>"How fast is it changing?"</p>
                        </div>
                        <div class="column">
                            <h4 style="color: #ff6b6b;">Integrals</h4>
                            <p>Accumulated change</p>
                            <p>Area under curve</p>
                            <p>"How much total?"</p>
                        </div>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Calculus = study of change and accumulation</li>
                        <li>Key strategy: infinitely many infinitely small pieces</li>
                        <li>Derivatives and integrals are inverses (Fundamental Theorem)</li>
                        <li>Applicable to physics, economics, biology, engineering</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 59: Paradox of the Derivative -->
            <section class="topic-section" id="topic-59" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 59</span>
                    <h2>🤔 The Paradox of the Derivative</h2>
                    <p class="topic-subtitle">Instantaneous rate of change</p>
                </div>

                <div class="content-card">
                    <h3>The Paradox</h3>
                    <p><strong>Question:</strong> How can something have a "rate of change" at a single instant in time?</p>
                    <p>Rate means change divided by time. But at a single instant, no time passes, so we'd get 0/0!</p>
                    <p><strong>Solution:</strong> Limits! We find the rate as we approach that instant.</p>
                </div>

                <div class="content-card">
                    <h3>The Derivative Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Definition via Limits</div>
                        <div class="formula-main">f'(x) = lim[Δx→0] (f(x+Δx) - f(x)) / Δx</div>
                        <p>Slope of secant line → slope of tangent line</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Derivative Visualization</h3>
                    <canvas id="canvas-59" width="600" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Δx = <span id="label59dx">1.0</span></label>
                            <input type="range" id="slider59dx" min="0.1" max="2" value="1" step="0.1" class="slider">
                        </div>
                        <button class="btn btn-primary" id="btn59animate">Show Limit</button>
                    </div>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 VISUAL INTUITION</div>
                    <p>Draw a secant line between two points on a curve. As you bring the points closer together, the secant line approaches the tangent line. The derivative is the slope of that tangent line!</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Derivative = instantaneous rate of change</li>
                        <li>Paradox resolved using limits</li>
                        <li>Geometrically: slope of tangent line</li>
                        <li>Foundation for all of differential calculus</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 60: Derivative Formulas -->
            <section class="topic-section" id="topic-60" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 60</span>
                    <h2>📐 Derivative Formulas (Geometric)</h2>
                    <p class="topic-subtitle">Power rule, sum rule, and more</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Standard rules for computing derivatives without using limits every time.</p>
                    <p><strong>Why it matters:</strong> Makes calculus practical - we can quickly find derivatives of complex functions.</p>
                </div>
                <div class="content-card">
                    <h3>Common Derivative Rules</h3>
                    <div class="formula-card">
                        <div class="formula-header">Power Rule</div>
                        <div class="formula-main">d/dx(xⁿ) = nxⁿ⁻¹</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Sum Rule</div>
                        <div class="formula-main">d/dx[f(x) + g(x)] = f'(x) + g'(x)</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Constant Multiple</div>
                        <div class="formula-main">d/dx[cf(x)] = c·f'(x)</div>
                    </div>
                </div>
                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>f(x) = 3x⁴ - 2x² + 5</strong></p>
                    <p>f'(x) = 3·4x³ - 2·2x + 0</p>
                    <p>f'(x) = 12x³ - 4x</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Power rule: bring down exponent, subtract 1</li>
                        <li>Sum rule: derivative of sum = sum of derivatives</li>
                        <li>Constant multiple: constant comes out front</li>
                        <li>Makes computing derivatives fast and easy</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 61: Chain Rule & Product Rule -->
            <section class="topic-section" id="topic-61" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 61</span>
                    <h2>🔗 Chain Rule &amp; Product Rule</h2>
                    <p class="topic-subtitle">Derivatives of composite and multiplied functions</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Rules for finding derivatives of complex functions built from simpler ones.</p>
                </div>
                <div class="content-card">
                    <h3>The Rules</h3>
                    <div class="formula-card">
                        <div class="formula-header">Chain Rule</div>
                        <div class="formula-main">d/dx[f(g(x))] = f'(g(x)) · g'(x)</div>
                        <p>"Derivative of outside × derivative of inside"</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Product Rule</div>
                        <div class="formula-main">d/dx[f(x)g(x)] = f'(x)g(x) + f(x)g'(x)</div>
                        <p>"First times derivative of second + second times derivative of first"</p>
                    </div>
                </div>
                <div class="callout-box example">
                    <div class="callout-header">📊 CHAIN RULE EXAMPLE</div>
                    <p><strong>f(x) = (3x² + 1)⁵</strong></p>
                    <p>Let u = 3x² + 1, so f = u⁵</p>
                    <p>f'(x) = 5u⁴ · 6x = 5(3x² + 1)⁴ · 6x</p>
                    <p>f'(x) = 30x(3x² + 1)⁴</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Chain rule for composed functions: outer' × inner'</li>
                        <li>Product rule for multiplied functions: f'g + fg'</li>
                        <li>Essential for complex derivatives</li>
                        <li>Also: Quotient rule for division</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 62: Derivative of e^x -->
            <section class="topic-section" id="topic-62" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 62</span>
                    <h2>ℯ Derivative of eˣ</h2>
                    <p class="topic-subtitle">The function that is its own derivative</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The exponential function eˣ has the remarkable property that its derivative equals itself!</p>
                    <p><strong>Why it matters:</strong> e appears throughout nature - growth, decay, compound interest, probability.</p>
                </div>
                <div class="content-card">
                    <h3>The Special Property</h3>
                    <div class="formula-card">
                        <div class="formula-header">Derivative of eˣ</div>
                        <div class="formula-main">d/dx(eˣ) = eˣ</div>
                        <p>The ONLY function (up to constant multiple) that equals its own derivative!</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">General Exponential</div>
                        <div class="formula-main">d/dx(aˣ) = aˣ · ln(a)</div>
                    </div>
                </div>
                <div class="callout-box insight">
                    <div class="callout-header">💡 WHY e IS SPECIAL</div>
                    <p>e ≈ 2.71828... is defined so that the rate of change of eˣ at x=0 equals 1. This makes it the "natural" base for exponentials in calculus!</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>d/dx(eˣ) = eˣ (function = its own derivative)</li>
                        <li>e is the natural base (~2.71828)</li>
                        <li>Appears in growth/decay models</li>
                        <li>Foundation for differential equations</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 63: Implicit Differentiation -->
            <section class="topic-section" id="topic-63" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 63</span>
                    <h2>🔄 Implicit Differentiation</h2>
                    <p class="topic-subtitle">Derivatives when y isn't isolated</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Finding dy/dx when the equation isn't solved for y (like x² + y² = 25).</p>
                    <p><strong>Why it matters:</strong> Many relationships can't be expressed as y = f(x), but we still need derivatives.</p>
                </div>
                <div class="content-card">
                    <h3>Method</h3>
                    <ol>
                        <li>Differentiate both sides with respect to x</li>
                        <li>Treat y as a function of x (use chain rule)</li>
                        <li>Solve for dy/dx</li>
                    </ol>
                </div>
                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE: Circle</div>
                    <p><strong>x² + y² = 25</strong></p>
                    <p>Differentiate: 2x + 2y(dy/dx) = 0</p>
                    <p>Solve: dy/dx = -x/y</p>
                    <p>This gives the slope of the tangent line at any point on the circle!</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Used when equation isn't solved for y</li>
                        <li>Differentiate both sides with respect to x</li>
                        <li>Remember: d/dx(y) = dy/dx (chain rule)</li>
                        <li>Solve algebraically for dy/dx</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 64: Integrals -->
            <section class="topic-section" id="topic-64" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 64</span>
                    <h2>∫ Integrals</h2>
                    <p class="topic-subtitle">Area and accumulation</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Integration sums infinitely many infinitely small pieces. Visually, it's the area under a curve.</p>
                    <p><strong>Why it matters:</strong> Calculates total distance from velocity, total profit from marginal profit, total probability from density functions.</p>
                </div>

                <div class="content-card">
                    <h3>Riemann Sums</h3>
                    <div class="formula-card">
                        <div class="formula-header">Approximation</div>
                        <div class="formula-main">∑ f(xᵢ) Δx</div>
                        <p>Sum of rectangle areas = height × width</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Integral (Exact)</div>
                        <div class="formula-main">∫ᵃᵇ f(x) dx = lim[Δx→0] ∑ f(xᵢ) Δx</div>
                        <p>As rectangles get infinitely thin, sum approaches exact area</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Riemann Sum Visualization</h3>
                    <canvas id="canvas-64" width="600" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Rectangles: <span id="label64n">8</span></label>
                            <input type="range" id="slider64n" min="4" max="50" value="8" step="1" class="slider">
                        </div>
                        <button class="btn btn-primary" id="btn64animate">Animate Convergence</button>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Integral = area under curve = accumulated change</li>
                        <li>Riemann sums approximate with rectangles</li>
                        <li>As Δx → 0, approximation becomes exact</li>
                        <li>Notation: ∫ means "sum" in continuous sense</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 65: Fundamental Theorem of Calculus -->
            <section class="topic-section" id="topic-65" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 65</span>
                    <h2>⚖️ Fundamental Theorem of Calculus</h2>
                    <p class="topic-subtitle">The bridge connecting derivatives and integrals</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The most important theorem in calculus - it shows that derivatives and integrals are inverse operations!</p>
                    <p><strong>Why it matters:</strong> Lets us compute integrals using antiderivatives instead of limits of Riemann sums.</p>
                </div>
                <div class="content-card">
                    <h3>The Two Parts</h3>
                    <div class="formula-card">
                        <div class="formula-header">Part 1</div>
                        <div class="formula-main">d/dx[∫ᵃˣ f(t) dt] = f(x)</div>
                        <p>Derivative of integral = original function</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Part 2</div>
                        <div class="formula-main">∫ᵃᵇ f(x) dx = F(b) - F(a)</div>
                        <p>Where F'(x) = f(x) (F is antiderivative of f)</p>
                    </div>
                </div>
                <div class="callout-box insight">
                    <div class="callout-header">💡 THE BIG IDEA</div>
                    <p>Integration and differentiation are opposite operations, like multiplication and division. This means we can evaluate integrals by finding antiderivatives!</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Derivatives and integrals are inverses</li>
                        <li>∫ᵃᵇ f(x) dx = F(b) - F(a) where F' = f</li>
                        <li>Makes integration practical (no limits!)</li>
                        <li>Most important theorem in calculus</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 66: Area and Slope Connection -->
            <section class="topic-section" id="topic-66" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 66</span>
                    <h2>📊 Area and Slope Connection</h2>
                    <p class="topic-subtitle">Why integrals and derivatives are inverses</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> A deeper look at why the Fundamental Theorem works - the geometric intuition behind the connection.</p>
                </div>
                <div class="content-card">
                    <h3>The Connection</h3>
                    <p><strong>Area accumulation:</strong> As you move right, area under curve accumulates. The RATE of this accumulation equals the height of the curve!</p>
                    <p>If A(x) = area from 0 to x, then A'(x) = height at x = f(x)</p>
                    <p>This is WHY derivatives and integrals are inverses!</p>
                </div>
                <div class="callout-box insight">
                    <div class="callout-header">💡 GEOMETRIC INTUITION</div>
                    <p>Imagine filling a container with water. The accumulated water (integral) grows at a rate equal to the flow rate (derivative). The RATE of area accumulation equals the height!</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Area accumulation rate = curve height</li>
                        <li>Explains why d/dx[∫ f] = f</li>
                        <li>Geometric understanding of FTC</li>
                        <li>Slope and area are inverse concepts</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 67: Higher Order Derivatives -->
            <section class="topic-section" id="topic-67" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 67</span>
                    <h2>📈 Higher Order Derivatives</h2>
                    <p class="topic-subtitle">Derivatives of derivatives</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Taking the derivative multiple times: f'(x), f''(x), f'''(x), ...</p>
                    <p><strong>Why it matters:</strong> Used in physics (acceleration is second derivative of position), optimization (concavity), and approximations.</p>
                </div>
                <div class="content-card">
                    <h3>Notation and Meaning</h3>
                    <div class="formula-card">
                        <div class="formula-header">Second Derivative</div>
                        <div class="formula-main">f''(x) = d²f/dx²</div>
                        <p>Rate of change of the rate of change</p>
                        <p>Measures concavity (curving up or down)</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Third Derivative</div>
                        <div class="formula-main">f'''(x) = d³f/dx³</div>
                        <p>Rate of change of acceleration (jerk)</p>
                    </div>
                </div>
                <div class="content-card">
                    <h3>Physical Interpretation</h3>
                    <ul>
                        <li><strong>Position:</strong> s(t)</li>
                        <li><strong>Velocity:</strong> v(t) = s'(t)</li>
                        <li><strong>Acceleration:</strong> a(t) = s''(t) = v'(t)</li>
                        <li><strong>Jerk:</strong> j(t) = s'''(t) = a'(t)</li>
                    </ul>
                </div>
                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>f(x) = x⁴</strong></p>
                    <p>f'(x) = 4x³</p>
                    <p>f''(x) = 12x²</p>
                    <p>f'''(x) = 24x</p>
                    <p>f⁴(x) = 24</p>
                    <p>f⁵(x) = 0</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>f''(x) measures concavity</li>
                        <li>In physics: position → velocity → acceleration</li>
                        <li>Used in Taylor series and optimization</li>
                        <li>Can take derivative as many times as you want</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 68: Taylor Series -->
            <section class="topic-section" id="topic-68" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 68</span>
                    <h2>∞ Taylor Series</h2>
                    <p class="topic-subtitle">Functions as infinite polynomials</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Any smooth function can be approximated as an infinite polynomial centered at a point.</p>
                    <p><strong>Why it matters:</strong> Computers can't calculate sin(x) directly, but they can calculate polynomials. Taylor series makes complex functions computable!</p>
                </div>

                <div class="content-card">
                    <h3>The Formula</h3>
                    <div class="formula-card">
                        <div class="formula-header">Taylor Series at x=a</div>
                        <div class="formula-main">f(x) = ∑ fⁿⁿⁿᵒⁿ(a)/n! · (x-a)ⁿ</div>
                        <p>= f(a) + f'(a)(x-a) + f''(a)(x-a)²/2! + f'''(a)(x-a)³/3! + ...</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Maclaurin Series (a=0)</div>
                        <div class="formula-main">f(x) = f(0) + f'(0)x + f''(0)x²/2! + ...</div>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Taylor Approximation</h3>
                    <canvas id="canvas-68" width="600" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Degree: <span id="label68degree">1</span></label>
                            <input type="range" id="slider68degree" min="1" max="10" value="1" step="1" class="slider">
                        </div>
                        <select id="select68func" class="form-control">
                            <option value="sin">sin(x)</option>
                            <option value="cos">cos(x)</option>
                            <option value="exp">eˣ</option>
                        </select>
                    </div>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 FAMOUS EXAMPLES</div>
                    <div class="example-solution">
                        <p><strong>eˣ = 1 + x + x²/2! + x³/3! + x⁴/4! + ...</strong></p>
                        <p><strong>sin(x) = x - x³/3! + x⁵/5! - x⁷/7! + ...</strong></p>
                        <p><strong>cos(x) = 1 - x²/2! + x⁴/4! - x⁶/6! + ...</strong></p>
                    </div>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Any smooth function = infinite polynomial</li>
                        <li>Formula uses derivatives at a single point</li>
                        <li>More terms = better approximation</li>
                        <li>How computers calculate sin, cos, eˣ, etc.</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 69: Limits (ε-δ Definition) -->
            <section class="topic-section" id="topic-69" data-subject="calculus" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 69</span>
                    <h2>∞ Limits (ε-δ Definition)</h2>
                    <p class="topic-subtitle">The rigorous foundation of calculus</p>
                </div>
                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The precise, formal definition of a limit that makes calculus mathematically rigorous.</p>
                    <p><strong>Why it matters:</strong> Puts calculus on a solid logical foundation. Before this (1800s), calculus worked but wasn't rigorously justified.</p>
                </div>
                <div class="content-card">
                    <h3>The Formal Definition</h3>
                    <div class="formula-card">
                        <div class="formula-header">ε-δ Definition of Limit</div>
                        <div class="formula-main">lim[ₓ→ᵃ] f(x) = L</div>
                        <p><strong>Means:</strong> For every ε &gt; 0, there exists δ &gt; 0 such that:</p>
                        <p>If 0 &lt; |x - a| &lt; δ, then |f(x) - L| &lt; ε</p>
                    </div>
                </div>
                <div class="callout-box insight">
                    <div class="callout-header">💡 IN PLAIN ENGLISH</div>
                    <p>"We can make f(x) arbitrarily close to L (ε-close) by making x sufficiently close to a (δ-close)."</p>
                    <p>ε (epsilon) = how close we want to be to L</p>
                    <p>δ (delta) = how close we need to be to a</p>
                    <p>The limit exists if, for ANY ε challenge, we can find a δ response that works.</p>
                </div>
                <div class="content-card">
                    <h3>Why This Matters</h3>
                    <ul>
                        <li><strong>Removes vagueness:</strong> "approaching" becomes precise</li>
                        <li><strong>Handles edge cases:</strong> Defines exactly when limits exist</li>
                        <li><strong>Foundation for proofs:</strong> All calculus theorems proven from this</li>
                        <li><strong>Historical importance:</strong> Made calculus rigorous (Cauchy, Weierstrass)</li>
                    </ul>
                </div>
                <div class="callout-box example">
                    <div class="callout-header">📊 SIMPLE EXAMPLE</div>
                    <p><strong>Prove: lim[ₓ→2] (3x - 1) = 5</strong></p>
                    <p>Want: |f(x) - 5| &lt; ε</p>
                    <p>|(3x - 1) - 5| &lt; ε</p>
                    <p>|3x - 6| &lt; ε</p>
                    <p>3|x - 2| &lt; ε</p>
                    <p>|x - 2| &lt; ε/3</p>
                    <p><strong>Choose δ = ε/3</strong>, and the proof works!</p>
                </div>
                <div class="callout-box warning">
                    <div class="callout-header">⚠️ DON'T PANIC</div>
                    <p>This definition looks scary but you don't need it for most calculus! It's the logical foundation, but you can use intuitive limits for practical work. Think of it like knowing a car's engine works even if you just drive it normally.</p>
                </div>
                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Formal definition: for all ε &gt; 0, exists δ &gt; 0...</li>
                        <li>Makes "approaching" mathematically precise</li>
                        <li>Foundation of all calculus rigor</li>
                        <li>You can do calculus without memorizing this (but it's important conceptually)</li>
                    </ul>
                </div>
            </section>

            <!-- DATA SCIENCE TOPICS (70-85) -->

            <!-- Topic 70: Simple Linear Regression -->
            <section class="topic-section" id="topic-70" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 70</span>
                    <h2>📈 Simple Linear Regression</h2>
                    <p class="topic-subtitle">Modeling relationships between two continuous variables</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Simple linear regression models the relationship between a dependent variable (y) and an independent variable (x) using a straight line.</p>
                    <p><strong>Why it matters:</strong> Foundation for predictive modeling. Used everywhere from business forecasting to scientific research.</p>
                    <p><strong>When to use it:</strong> When you have two continuous variables and want to predict one from the other.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD ANALOGY</div>
                    <p>Like drawing the best-fit line through scattered points on a graph. Imagine plotting house prices vs square footage - regression finds the line that best describes this relationship!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Linear Equation</div>
                        <div class="formula-main">y = a + bx</div>
                        <p>a = intercept (where line crosses y-axis)</p>
                        <p>b = slope (change in y per unit change in x)</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Calculating Slope (b)</div>
                        <div class="formula-main">b = Σ(x-x̄)(y-ȳ) / Σ(x-x̄)²</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Calculating Intercept (a)</div>
                        <div class="formula-main">a = ȳ - b·x̄</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Least Squares Method</div>
                        <div class="formula-main">Minimize: Σ(yᵢ - ŷᵢ)²</div>
                        <p>Find line that minimizes sum of squared residuals</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Interactive Regression Line</h3>
                    <canvas id="canvas-70" width="700" height="400"></canvas>
                    <div class="controls">
                        <button class="btn btn-primary" id="btn70fit">Fit Regression Line</button>
                        <button class="btn btn-secondary" id="btn70reset">Reset</button>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Real Estate:</strong> Predicting house prices from square footage</li>
                        <li><strong>Business:</strong> Sales forecasting from advertising spend</li>
                        <li><strong>Economics:</strong> Demand prediction from price changes</li>
                        <li><strong>Science:</strong> Temperature vs ice cream sales</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Assuming correlation = causation:</strong> Just because two variables are related doesn't mean one causes the other!</p>
                    <p><strong>Extrapolating beyond data:</strong> Don't predict values far outside your training data range.</p>
                    <p><strong>Ignoring outliers:</strong> Extreme values can heavily distort your regression line.</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Check residual plots for patterns (should be random)</p>
                    <p>• Calculate R² to assess fit quality (closer to 1 = better)</p>
                    <p>• Use for prediction only within your data range</p>
                    <p>• Always visualize your data first (Anscombe's quartet!)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>y = a + bx models linear relationship</li>
                        <li>Least squares minimizes prediction errors</li>
                        <li>b = slope, a = intercept</li>
                        <li>R² measures goodness of fit (0 to 1)</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 71: Multiple Linear Regression -->
            <section class="topic-section" id="topic-71" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 71</span>
                    <h2>🔢 Multiple Linear Regression</h2>
                    <p class="topic-subtitle">Extending to multiple predictor variables</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Multiple linear regression extends simple regression to handle multiple independent variables simultaneously.</p>
                    <p><strong>Why it matters:</strong> Real-world outcomes usually depend on multiple factors, not just one!</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 REAL-WORLD EXAMPLE</div>
                    <p>Like having multiple factors influencing an outcome - house price depends on size, location, age, bedrooms, etc. Multiple regression handles all of these together!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Multiple Regression Equation</div>
                        <div class="formula-main">y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε</div>
                        <p>β₀ = intercept, βᵢ = coefficients, ε = error term</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Matrix Form</div>
                        <div class="formula-main">Y = Xβ + ε</div>
                        <p>Normal equation: β = (XᵀX)⁻¹XᵀY</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Housing Prices:</strong> Predict from size, location, age, bedrooms, bathrooms</li>
                        <li><strong>Student Performance:</strong> Model grades from study hours, attendance, prior GPA</li>
                        <li><strong>Business Revenue:</strong> Forecast from marketing, seasonality, competition</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Multicollinearity:</strong> When predictors are highly correlated with each other</p>
                    <p><strong>Including irrelevant variables:</strong> More variables ≠ better model</p>
                    <p><strong>Not scaling features:</strong> Variables on different scales can cause issues</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Check VIF (Variance Inflation Factor) for multicollinearity</p>
                    <p>• Use feature selection techniques to identify important variables</p>
                    <p>• Standardize variables before modeling</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Extends simple regression to multiple predictors</li>
                        <li>y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ</li>
                        <li>Matrix form: β = (XᵀX)⁻¹XᵀY</li>
                        <li>Watch for multicollinearity between predictors</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 72: Logistic Regression -->
            <section class="topic-section" id="topic-72" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 72</span>
                    <h2>🎯 Logistic Regression</h2>
                    <p class="topic-subtitle">Classification instead of continuous prediction</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Logistic regression predicts binary outcomes (0/1, Yes/No, Pass/Fail) using a sigmoid function.</p>
                    <p><strong>Why it matters:</strong> Essential for classification problems - spam detection, disease diagnosis, customer churn.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 ANALOGY</div>
                    <p>Like a switch - given inputs, predict ON/OFF, YES/NO, PASS/FAIL. Unlike linear regression (predicts any number), logistic gives probability between 0 and 1!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Logistic Function (Sigmoid)</div>
                        <div class="formula-main">z = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ</div>
                        <div class="formula-main">σ(z) = 1 / (1 + e⁻ᶻ)</div>
                        <div class="formula-main">P(y=1) = σ(z)</div>
                        <p>Decision: if P ≥ 0.5 → class 1, else class 0</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Sigmoid Curve Visualization</h3>
                    <canvas id="canvas-72" width="700" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Threshold: <span id="label72">0.5</span></label>
                            <input type="range" id="slider72" min="0" max="1" value="0.5" step="0.05" class="slider">
                        </div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Email Spam Detection:</strong> Spam or Not Spam?</li>
                        <li><strong>Medical Diagnosis:</strong> Disease present or absent?</li>
                        <li><strong>Loan Default:</strong> Will customer default?</li>
                        <li><strong>Customer Churn:</strong> Will customer leave?</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Interpreting output as continuous:</strong> Output is probability, not direct prediction</p>
                    <p><strong>Not scaling features:</strong> Can affect convergence</p>
                    <p><strong>Ignoring class imbalance:</strong> When one class dominates, model becomes biased</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Use log-loss (cross-entropy) for evaluation, not MSE</p>
                    <p>• Adjust threshold based on cost of false positives vs false negatives</p>
                    <p>• Check confusion matrix for detailed performance</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Logistic regression for binary classification</li>
                        <li>Sigmoid function: σ(z) = 1/(1+e⁻ᶻ)</li>
                        <li>Output is probability P(y=1)</li>
                        <li>Decision boundary at P = 0.5 (adjustable)</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 73: ANOVA -->
            <section class="topic-section" id="topic-73" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 73</span>
                    <h2>⚖️ ANOVA (Analysis of Variance)</h2>
                    <p class="topic-subtitle">Comparing means of 3+ groups</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> ANOVA tests whether the means of three or more groups are significantly different.</p>
                    <p><strong>Why it matters:</strong> More powerful than multiple t-tests. Avoids inflated Type I error rate.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 EXAMPLE</div>
                    <p>Testing if different teaching methods (A, B, C) produce different average test scores. Instead of 3 separate t-tests, ANOVA does it all at once!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Sum of Squares Decomposition</div>
                        <div class="formula-main">SST = SSB + SSW</div>
                        <p>Total = Between Groups + Within Groups</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">SST (Total Sum of Squares)</div>
                        <div class="formula-main">SST = Σᵢ Σⱼ (yᵢⱼ - ȳ)²</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">SSB (Between Groups)</div>
                        <div class="formula-main">SSB = Σᵢ nᵢ(ȳᵢ - ȳ)²</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">SSW (Within Groups)</div>
                        <div class="formula-main">SSW = Σᵢ Σⱼ (yᵢⱼ - ȳᵢ)²</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">F-Statistic</div>
                        <div class="formula-main">F = MSB/MSW = [SSB/(k-1)] / [SSW/(N-k)]</div>
                        <p>k = number of groups, N = total observations</p>
                        <p>H₀: μ₁ = μ₂ = μ₃ = ... (all means equal)</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Medical Research:</strong> Comparing effectiveness of 3+ drugs</li>
                        <li><strong>Marketing:</strong> A/B/C testing multiple ad variations</li>
                        <li><strong>Quality Control:</strong> Comparing output across factories</li>
                        <li><strong>Education:</strong> Comparing teaching methods</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Using multiple t-tests:</strong> Increases Type I error rate (family-wise error)</p>
                    <p><strong>Not checking assumptions:</strong> Normality and homogeneity of variance required</p>
                    <p><strong>Forgetting post-hoc tests:</strong> ANOVA tells you groups differ, not which ones</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Use Tukey's HSD for post-hoc pairwise comparisons</p>
                    <p>• Check homogeneity of variance with Levene's test</p>
                    <p>• If assumptions violated, use Kruskal-Wallis (non-parametric alternative)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>ANOVA compares means of 3+ groups</li>
                        <li>F = MSB/MSW measures between vs within group variation</li>
                        <li>SST = SSB + SSW</li>
                        <li>Post-hoc tests identify which groups differ</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 74: Polynomial Regression -->
            <section class="topic-section" id="topic-74" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 74</span>
                    <h2>📈 Polynomial Regression</h2>
                    <p class="topic-subtitle">Fitting curves instead of lines</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Polynomial regression fits curved relationships by including higher-order terms (x², x³, etc.).</p>
                    <p><strong>Why it matters:</strong> Many relationships aren't linear - think projectile motion, growth curves, economic trends.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 ANALOGY</div>
                    <p>When relationship is curved, not straight - like throwing a ball (parabola) or bacterial growth (exponential). Polynomial regression captures these curves!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Polynomial Equation</div>
                        <div class="formula-main">y = β₀ + β₁x + β₂x² + β₃x³ + ... + βₙxⁿ</div>
                        <p>n = degree of polynomial</p>
                        <p>Still linear in coefficients! (uses same methods as linear regression)</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Polynomial Degree Visualization</h3>
                    <canvas id="canvas-74" width="700" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Degree: <span id="label74">1</span></label>
                            <input type="range" id="slider74" min="1" max="10" value="1" step="1" class="slider">
                        </div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Growth Curves:</strong> Population, bacterial, economic growth</li>
                        <li><strong>Physics:</strong> Projectile motion, acceleration</li>
                        <li><strong>Chemistry:</strong> Reaction rates</li>
                        <li><strong>Economics:</strong> Marginal cost curves</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Overfitting:</strong> Too high degree fits noise, not signal</p>
                    <p><strong>Extrapolation disaster:</strong> Polynomials behave wildly outside training range</p>
                    <p><strong>Ignoring R² plateau:</strong> More complexity doesn't always improve fit</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Use cross-validation to select optimal degree</p>
                    <p>• Consider regularization (Ridge/Lasso) for high degrees</p>
                    <p>• Start simple (degree 2-3), increase only if needed</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Fits curved relationships: y = β₀ + β₁x + β₂x² + ...</li>
                        <li>Higher degree = more flexible curve</li>
                        <li>Still linear in coefficients (same fitting method)</li>
                        <li>Watch for overfitting with high degrees</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 75: R² & Model Evaluation -->
            <section class="topic-section" id="topic-75" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 75</span>
                    <h2>🎯 R² and Model Evaluation</h2>
                    <p class="topic-subtitle">Measuring how well model fits data</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> R² (coefficient of determination) measures the proportion of variance explained by the model.</p>
                    <p><strong>Why it matters:</strong> Tells you if your model is actually useful or just garbage!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">R² Formula</div>
                        <div class="formula-main">R² = 1 - (SSᵣₑₛ / SSₜₒₜ)</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Residual Sum of Squares</div>
                        <div class="formula-main">SSᵣₑₛ = Σ(y - ŷ)²</div>
                        <p>Sum of squared prediction errors</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Total Sum of Squares</div>
                        <div class="formula-main">SSₜₒₜ = Σ(y - ȳ)²</div>
                        <p>Total variance in y</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Adjusted R²</div>
                        <div class="formula-main">Adjusted R² = 1 - [(1-R²)(n-1)/(n-k-1)]</div>
                        <p>Penalizes adding unnecessary variables</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Interpretation</h3>
                    <ul>
                        <li><strong>R² = 1:</strong> Perfect fit (predicts all variance)</li>
                        <li><strong>R² = 0.9:</strong> Excellent (90% variance explained)</li>
                        <li><strong>R² = 0.7:</strong> Good fit</li>
                        <li><strong>R² = 0.5:</strong> Moderate fit</li>
                        <li><strong>R² = 0:</strong> Model no better than mean</li>
                        <li><strong>R² &lt; 0:</strong> Model worse than just using mean!</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Other Evaluation Metrics</h3>
                    <ul>
                        <li><strong>MSE (Mean Squared Error):</strong> Average squared prediction error</li>
                        <li><strong>RMSE (Root MSE):</strong> Same units as y, easier to interpret</li>
                        <li><strong>MAE (Mean Absolute Error):</strong> Less sensitive to outliers</li>
                        <li><strong>AIC/BIC:</strong> For model comparison (lower is better)</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>R² always increases with more variables:</strong> Use Adjusted R² instead</p>
                    <p><strong>High R² doesn't mean causation:</strong> Can have perfect correlation with no causal link</p>
                    <p><strong>Ignoring residual plots:</strong> R² alone doesn't catch all problems</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Always plot residuals vs fitted values (should be random)</p>
                    <p>• Use cross-validation for realistic performance estimate</p>
                    <p>• Report multiple metrics, not just R²</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>R² = proportion of variance explained (0 to 1)</li>
                        <li>R² = 1 - SSᵣₑₛ/SSₜₒₜ</li>
                        <li>Adjusted R² penalizes adding variables</li>
                        <li>Use alongside other metrics (RMSE, MAE)</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 76: SVD -->
            <section class="topic-section" id="topic-76" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 76</span>
                    <h2>🔢 Singular Value Decomposition (SVD)</h2>
                    <p class="topic-subtitle">Matrix factorization technique</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> SVD decomposes any matrix into three matrices representing rotations and scaling.</p>
                    <p><strong>Why it matters:</strong> Powers Netflix recommendations, image compression, PCA, and data science applications everywhere!</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 ANALOGY</div>
                    <p>Breaking down a complex transformation into simpler rotations and stretches - like decomposing a complicated dance move into: rotate, stretch, rotate again!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">SVD Decomposition</div>
                        <div class="formula-main">A = UΣVᵀ</div>
                        <p>U = left singular vectors (orthogonal)</p>
                        <p>Σ = diagonal matrix of singular values</p>
                        <p>V = right singular vectors (orthogonal)</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Image Compression:</strong> Keep only top singular values for compressed images</li>
                        <li><strong>Recommender Systems:</strong> Netflix, Amazon product recommendations</li>
                        <li><strong>Dimensionality Reduction:</strong> Reduce features while keeping information</li>
                        <li><strong>PCA:</strong> Principal Component Analysis uses SVD internally</li>
                        <li><strong>Noise Reduction:</strong> Filter out small singular values = noise</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Confusing with eigendecomposition:</strong> SVD works on any matrix, eigen only on square</p>
                    <p><strong>Not sorting singular values:</strong> Always ordered largest to smallest</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Truncate to top k singular values for compression</p>
                    <p>• Largest singular values capture most important patterns</p>
                    <p>• Used in every major ML library (scikit-learn, TensorFlow)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>A = UΣVᵀ factorization</li>
                        <li>Works on any m×n matrix</li>
                        <li>Singular values = importance of each component</li>
                        <li>Foundation for PCA and recommender systems</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 77: PCA -->
            <section class="topic-section" id="topic-77" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 77</span>
                    <h2>🎯 Principal Component Analysis (PCA)</h2>
                    <p class="topic-subtitle">Dimensionality reduction using variance</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> PCA finds the most important directions (principal components) in high-dimensional data.</p>
                    <p><strong>Why it matters:</strong> Reduce 1000 features to 10 while keeping most information. Essential for visualization and ML!</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 ANALOGY</div>
                    <p>Finding the most important directions in high-dimensional data. Like taking a photo of a 3D object - you pick the best angle that captures the most detail!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">PCA Algorithm</div>
                        <p>1. Standardize data (mean=0, variance=1)</p>
                        <p>2. Compute covariance matrix: C = XᵀX/(n-1)</p>
                        <p>3. Find eigenvectors and eigenvalues of C</p>
                        <p>4. Sort by eigenvalue (largest = most variance)</p>
                        <p>5. Project data: Z = X·W (W = top eigenvectors)</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>PCA Projection Visualization</h3>
                    <canvas id="canvas-77" width="700" height="400"></canvas>
                    <div class="controls">
                        <button class="btn btn-primary" id="btn77project">Show PC Directions</button>
                        <button class="btn btn-secondary" id="btn77reset">Reset</button>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Feature Reduction:</strong> 100 features → 10 principal components</li>
                        <li><strong>Data Visualization:</strong> Plot high-dimensional data in 2D/3D</li>
                        <li><strong>Noise Reduction:</strong> Remove components with low variance</li>
                        <li><strong>Face Recognition:</strong> Eigenfaces technique</li>
                        <li><strong>Genomics:</strong> Reduce thousands of gene expressions</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Not scaling features first:</strong> PCA is sensitive to scale!</p>
                    <p><strong>Keeping too few/many components:</strong> Check cumulative variance explained</p>
                    <p><strong>Using on categorical data:</strong> PCA is for continuous variables</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Always standardize before PCA</p>
                    <p>• Use scree plot to choose number of components</p>
                    <p>• Aim for 80-95% cumulative variance explained</p>
                    <p>• Interpret PCs using loadings (which features matter most)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Finds directions of maximum variance</li>
                        <li>Based on eigenvectors of covariance matrix</li>
                        <li>Must standardize features first</li>
                        <li>Reduces dimensions while preserving information</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 78: Matrix Decompositions -->
            <section class="topic-section" id="topic-78" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 78</span>
                    <h2>🔢 Matrix Decompositions</h2>
                    <p class="topic-subtitle">LU, QR, Cholesky factorizations</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Methods to factor matrices into products of simpler matrices for efficient computation.</p>
                    <p><strong>Why it matters:</strong> Makes solving large systems fast and numerically stable.</p>
                </div>

                <div class="content-card">
                    <h3>Types of Decompositions</h3>
                    <div class="formula-card">
                        <div class="formula-header">LU Decomposition</div>
                        <div class="formula-main">A = LU</div>
                        <p>L = lower triangular, U = upper triangular</p>
                        <p>Use: Solving linear systems efficiently</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">QR Decomposition</div>
                        <div class="formula-main">A = QR</div>
                        <p>Q = orthogonal matrix, R = upper triangular</p>
                        <p>Use: Least squares problems, eigenvalue algorithms</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Cholesky Decomposition</div>
                        <div class="formula-main">A = LLᵀ</div>
                        <p>For positive definite matrices only</p>
                        <p>Use: Faster than LU for symmetric matrices</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Linear Systems:</strong> Solve Ax=b efficiently</li>
                        <li><strong>Least Squares:</strong> Linear regression uses QR</li>
                        <li><strong>Numerical Stability:</strong> Better than direct methods</li>
                        <li><strong>Machine Learning:</strong> Many algorithms use these internally</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>LU: A = LU (general matrices)</li>
                        <li>QR: A = QR (least squares)</li>
                        <li>Cholesky: A = LLᵀ (positive definite)</li>
                        <li>Improve computational efficiency and stability</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 79: Norms & Distance -->
            <section class="topic-section" id="topic-79" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 79</span>
                    <h2>📏 Norms and Distance Metrics</h2>
                    <p class="topic-subtitle">Measuring vector magnitude and distance</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Norms measure the "size" of vectors. Distance metrics measure how far apart vectors are.</p>
                    <p><strong>Why it matters:</strong> Essential for regularization (L1/L2), clustering, nearest neighbors, and optimization.</p>
                </div>

                <div class="content-card">
                    <h3>Common Norms</h3>
                    <div class="formula-card">
                        <div class="formula-header">L₁ Norm (Manhattan Distance)</div>
                        <div class="formula-main">||x||₁ = Σ|xᵢ|</div>
                        <p>Sum of absolute values</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">L₂ Norm (Euclidean Distance)</div>
                        <div class="formula-main">||x||₂ = √(Σxᵢ²)</div>
                        <p>Standard distance formula</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">L∞ Norm (Maximum Norm)</div>
                        <div class="formula-main">||x||∞ = max|xᵢ|</div>
                        <p>Largest component</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Regularization:</strong> L1 (Lasso), L2 (Ridge) regression</li>
                        <li><strong>K-Nearest Neighbors:</strong> Uses distance to find similar points</li>
                        <li><strong>Clustering:</strong> K-means uses Euclidean distance</li>
                        <li><strong>Optimization:</strong> Gradient descent minimizes norms</li>
                    </ul>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ KEY DIFFERENCES</div>
                    <p>• L₁: Encourages sparsity (many zeros)</p>
                    <p>• L₂: Smooth, differentiable everywhere</p>
                    <p>• L∞: Focuses on largest element</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>L₁: ||x||₁ = Σ|xᵢ| (Manhattan)</li>
                        <li>L₂: ||x||₂ = √Σxᵢ² (Euclidean)</li>
                        <li>L∞: ||x||∞ = max|xᵢ|</li>
                        <li>Used in regularization and distance calculations</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 80: Gradient Descent -->
            <section class="topic-section" id="topic-80" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 80</span>
                    <h2>📉 Gradient Descent</h2>
                    <p class="topic-subtitle">Iterative optimization algorithm</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Gradient descent is an iterative algorithm that finds minimum of a function by following the negative gradient.</p>
                    <p><strong>Why it matters:</strong> Powers ALL modern machine learning! Neural networks, linear regression, everything uses gradient descent.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 ANALOGY</div>
                    <p>Walking downhill to find the valley - taking steps in the steepest descent direction. Learning rate = step size. Too big = overshoot, too small = slow!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Gradient Descent Update Rule</div>
                        <div class="formula-main">θₜ₊₁ = θₜ - α·∇f(θₜ)</div>
                        <p>θ = parameters to optimize</p>
                        <p>α = learning rate (step size)</p>
                        <p>∇f = gradient (direction of steepest ascent)</p>
                        <p>We go NEGATIVE gradient to descend!</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Gradient Descent Visualization</h3>
                    <canvas id="canvas-80" width="700" height="400"></canvas>
                    <div class="controls">
                        <div class="slider-group">
                            <label>Learning Rate: <span id="label80">0.1</span></label>
                            <input type="range" id="slider80" min="0.01" max="0.5" value="0.1" step="0.01" class="slider">
                        </div>
                        <button class="btn btn-primary" id="btn80start">Start Descent</button>
                        <button class="btn btn-secondary" id="btn80reset">Reset</button>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Training Neural Networks:</strong> Backpropagation + gradient descent</li>
                        <li><strong>Linear Regression:</strong> Find optimal coefficients</li>
                        <li><strong>Logistic Regression:</strong> Minimize log-loss</li>
                        <li><strong>Any Differentiable Function:</strong> Find minimum</li>
                    </ul>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Learning rate too large:</strong> Diverges, overshoots minimum</p>
                    <p><strong>Learning rate too small:</strong> Converges very slowly</p>
                    <p><strong>Local minima:</strong> Can get stuck (less of issue with neural nets)</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Use learning rate scheduling (start big, decrease over time)</p>
                    <p>• Try different initializations to avoid bad local minima</p>
                    <p>• Monitor convergence with loss curve</p>
                    <p>• Typical learning rates: 0.001 to 0.1</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>θₜ₊₁ = θₜ - α∇f(θₜ)</li>
                        <li>Follow negative gradient to minimize function</li>
                        <li>Learning rate α controls step size</li>
                        <li>Foundation of ALL modern machine learning</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 81: SGD -->
            <section class="topic-section" id="topic-81" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 81</span>
                    <h2>⚡ Stochastic Gradient Descent (SGD)</h2>
                    <p class="topic-subtitle">Using random batches for efficiency</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> SGD updates parameters using a small random batch instead of the entire dataset.</p>
                    <p><strong>Why it matters:</strong> Much faster! Essential for large datasets and deep learning.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 KEY DIFFERENCE</div>
                    <p><strong>Batch GD:</strong> Use ALL data each step (slow but stable)</p>
                    <p><strong>SGD:</strong> Use ONE sample each step (fast but noisy)</p>
                    <p><strong>Mini-batch GD:</strong> Use small batch (e.g., 32 samples) - best of both!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">SGD Update</div>
                        <div class="formula-main">θₜ₊₁ = θₜ - α·∇f(θₜ; xᵢ:ᵢ₊ₙ)</div>
                        <p>Update using mini-batch of size n instead of full dataset</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Variants</h3>
                    <ul>
                        <li><strong>SGD with Momentum:</strong> Adds velocity term (smooths updates)</li>
                        <li><strong>Adam:</strong> Adaptive learning rates (most popular!)</li>
                        <li><strong>RMSprop:</strong> Divides by moving average of gradients</li>
                        <li><strong>AdaGrad:</strong> Adapts learning rate per parameter</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Deep Learning:</strong> Train neural networks on millions of examples</li>
                        <li><strong>Online Learning:</strong> Update model as new data arrives</li>
                        <li><strong>Large-scale ML:</strong> When data doesn't fit in memory</li>
                    </ul>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Mini-batch size: typically 32, 64, 128, or 256</p>
                    <p>• Shuffle data each epoch for better convergence</p>
                    <p>• Adam optimizer is good default choice</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Uses mini-batches instead of full dataset</li>
                        <li>Much faster than batch gradient descent</li>
                        <li>More noisy but often reaches good solution faster</li>
                        <li>Standard for training deep neural networks</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 82: Partial Derivatives -->
            <section class="topic-section" id="topic-82" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 82</span>
                    <h2>∂ Partial Derivatives</h2>
                    <p class="topic-subtitle">Derivatives with multiple variables</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Partial derivative measures rate of change with respect to ONE variable while holding others constant.</p>
                    <p><strong>Why it matters:</strong> Machine learning has many parameters - we need partial derivatives for all of them!</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Notation</div>
                        <div class="formula-main">∂f/∂x = rate of change w.r.t. x (hold y constant)</div>
                        <div class="formula-main">∂f/∂y = rate of change w.r.t. y (hold x constant)</div>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Example: f(x,y) = x² + xy + y²</div>
                        <div class="formula-main">∂f/∂x = 2x + y</div>
                        <div class="formula-main">∂f/∂y = x + 2y</div>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Geometric Interpretation</h3>
                    <p>Imagine a 3D surface f(x,y). The partial derivative ∂f/∂x is the slope if you walk in the x-direction only. ∂f/∂y is the slope in the y-direction.</p>
                </div>

                <div class="callout-box example">
                    <div class="callout-header">📊 EXAMPLE</div>
                    <p><strong>Function:</strong> f(x,y) = 3x²y + 2y³</p>
                    <p>∂f/∂x = 6xy (treat y as constant)</p>
                    <p>∂f/∂y = 3x² + 6y² (treat x as constant)</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Partial derivative w.r.t. one variable, others constant</li>
                        <li>Notation: ∂f/∂x or fₓ</li>
                        <li>Essential for multivariable optimization</li>
                        <li>Used in gradient calculation</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 83: Gradient & Jacobian -->
            <section class="topic-section" id="topic-83" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 83</span>
                    <h2>∇ Gradient and Jacobian</h2>
                    <p class="topic-subtitle">Organizing partial derivatives</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> The gradient collects all partial derivatives into a vector. The Jacobian is a matrix of partial derivatives.</p>
                    <p><strong>Why it matters:</strong> These are what gradient descent actually computes! Core of backpropagation.</p>
                </div>

                <div class="content-card">
                    <h3>Mathematical Foundation</h3>
                    <div class="formula-card">
                        <div class="formula-header">Gradient (for scalar function)</div>
                        <div class="formula-main">∇f = [∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ]</div>
                        <p>Vector pointing in direction of steepest ascent</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Jacobian (for vector function)</div>
                        <div class="formula-main">J = matrix of all first-order partial derivatives</div>
                        <p>Jᵢⱼ = ∂fᵢ/∂xⱼ</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Properties</h3>
                    <ul>
                        <li><strong>Gradient points uphill:</strong> Direction of steepest increase</li>
                        <li><strong>Gradient magnitude:</strong> How steep the slope is</li>
                        <li><strong>Perpendicular to level curves:</strong> Always perpendicular to contour lines</li>
                        <li><strong>Zero gradient:</strong> Local maximum, minimum, or saddle point</li>
                    </ul>
                </div>

                <div class="content-card">
                    <h3>Applications</h3>
                    <ul class="use-case-list">
                        <li><strong>Gradient Descent:</strong> Uses gradient to find minimum</li>
                        <li><strong>Backpropagation:</strong> Chain rule with Jacobians</li>
                        <li><strong>Neural Networks:</strong> Compute gradients for all weights</li>
                        <li><strong>Optimization:</strong> Any multivariable optimization problem</li>
                    </ul>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Gradient ∇f = vector of all partial derivatives</li>
                        <li>Points in direction of steepest ascent</li>
                        <li>Jacobian = matrix of partials for vector functions</li>
                        <li>Essential for backpropagation in neural networks</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 84: Convex Optimization -->
            <section class="topic-section" id="topic-84" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 84</span>
                    <h2>❓ Convex Optimization</h2>
                    <p class="topic-subtitle">Optimization with guaranteed global minimum</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> In convex optimization, any local minimum is also a global minimum - no getting stuck!</p>
                    <p><strong>Why it matters:</strong> Guarantees we find the best solution. Linear regression, SVM, many ML problems are convex.</p>
                </div>

                <div class="callout-box insight">
                    <div class="callout-header">💡 BOWL ANALOGY</div>
                    <p><strong>Convex:</strong> Like a bowl - roll a ball and it reaches the bottom (global minimum)</p>
                    <p><strong>Non-convex:</strong> Like mountains and valleys - ball gets stuck in local valleys</p>
                </div>

                <div class="content-card">
                    <h3>Key Concepts</h3>
                    <div class="formula-card">
                        <div class="formula-header">Convex Function</div>
                        <p>f(λx + (1-λ)y) ≤ λf(x) + (1-λ)f(y)</p>
                        <p>Line segment between any two points on graph lies above graph</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Convex Set</div>
                        <p>Line segment between any two points in set stays in set</p>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Examples</h3>
                    <ul>
                        <li><strong>Convex:</strong> Linear regression (MSE loss)</li>
                        <li><strong>Convex:</strong> Logistic regression (cross-entropy)</li>
                        <li><strong>Convex:</strong> Support Vector Machines</li>
                        <li><strong>Non-convex:</strong> Neural networks (but still works!)</li>
                    </ul>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ WHY IT MATTERS</div>
                    <p>• Convex: Any optimization algorithm finds global optimum</p>
                    <p>• Non-convex: Might get stuck in local minimum</p>
                    <p>• Deep learning is non-convex but works due to overparameterization</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Convex functions: local minimum = global minimum</li>
                        <li>Guarantees optimal solution</li>
                        <li>Linear/logistic regression, SVM are convex</li>
                        <li>Neural networks non-convex but still trainable</li>
                    </ul>
                </div>
            </section>

            <!-- Topic 85: Loss Functions -->
            <section class="topic-section" id="topic-85" data-subject="data-science" style="display: none;">
                <div class="topic-header">
                    <span class="topic-number">Topic 85</span>
                    <h2>🎯 Loss Functions</h2>
                    <p class="topic-subtitle">Measuring model error</p>
                </div>

                <div class="content-card">
                    <h3>Introduction</h3>
                    <p><strong>What is it?</strong> Loss functions quantify how wrong your model's predictions are. We minimize loss during training.</p>
                    <p><strong>Why it matters:</strong> Different problems need different loss functions. Wrong loss = bad model!</p>
                </div>

                <div class="content-card">
                    <h3>Common Loss Functions</h3>
                    <div class="formula-card">
                        <div class="formula-header">MSE (Mean Squared Error)</div>
                        <div class="formula-main">MSE = (1/n)Σ(y - ŷ)²</div>
                        <p>Use for: Regression problems</p>
                        <p>Penalizes large errors heavily</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">MAE (Mean Absolute Error)</div>
                        <div class="formula-main">MAE = (1/n)Σ|y - ŷ|</div>
                        <p>Use for: Regression (less sensitive to outliers)</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Cross-Entropy (Log Loss)</div>
                        <div class="formula-main">L = -Σy·log(ŷ)</div>
                        <p>Use for: Classification problems</p>
                        <p>Binary: -(y log(ŷ) + (1-y)log(1-ŷ))</p>
                    </div>
                    <div class="formula-card">
                        <div class="formula-header">Hinge Loss</div>
                        <div class="formula-main">L = max(0, 1 - y·ŷ)</div>
                        <p>Use for: Support Vector Machines</p>
                    </div>
                </div>

                <div class="interactive-container">
                    <h3>Loss Landscape Visualization</h3>
                    <canvas id="canvas-85" width="700" height="400"></canvas>
                    <div class="controls">
                        <select id="select85" class="form-control">
                            <option value="mse">MSE Loss</option>
                            <option value="mae">MAE Loss</option>
                            <option value="cross">Cross-Entropy</option>
                        </select>
                    </div>
                </div>

                <div class="content-card">
                    <h3>Choosing the Right Loss</h3>
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Problem Type</th>
                                <th>Loss Function</th>
                                <th>Why?</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Regression</td>
                                <td>MSE or MAE</td>
                                <td>MSE for smooth gradients, MAE for outliers</td>
                            </tr>
                            <tr>
                                <td>Binary Classification</td>
                                <td>Binary Cross-Entropy</td>
                                <td>Probabilistic interpretation</td>
                            </tr>
                            <tr>
                                <td>Multi-class</td>
                                <td>Categorical Cross-Entropy</td>
                                <td>Works with softmax output</td>
                            </tr>
                            <tr>
                                <td>SVM</td>
                                <td>Hinge Loss</td>
                                <td>Maximizes margin</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="callout-box warning">
                    <div class="callout-header">⚠️ COMMON MISTAKES</div>
                    <p><strong>Wrong loss for problem type:</strong> MSE for classification is bad!</p>
                    <p><strong>Not understanding loss behavior:</strong> Different losses encourage different solutions</p>
                    <p><strong>Ignoring regularization:</strong> Add L1/L2 penalty to prevent overfitting</p>
                </div>

                <div class="callout-box tip">
                    <div class="callout-header">✅ PRO TIPS</div>
                    <p>• Regression: MSE (default) or MAE (if outliers)</p>
                    <p>• Classification: Cross-Entropy (always!)</p>
                    <p>• Imbalanced classes: Use weighted loss</p>
                    <p>• Custom problems: Design custom loss function</p>
                </div>

                <div class="summary-card">
                    <h3>🎯 Key Takeaways</h3>
                    <ul>
                        <li>Loss measures model error</li>
                        <li>MSE/MAE for regression</li>
                        <li>Cross-Entropy for classification</li>
                        <li>Gradient descent minimizes loss</li>
                    </ul>
                </div>
            </section>

        </main>
    </div>

    <script src="app.js"></script>
</body>
</html>